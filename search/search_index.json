{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Machine Learning? Arthur Samuel described it as: \"The field of study that gives computers the ability to learn without being explicitly programmed.\" This is an older, informal definition. Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\" ML systems learn how to combine input to produce useful predictions on never-before-seen data. Example : playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning Unsupervised learning Supervised Learning In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. We try to extrapolate labels for new data given labelled data we already have Supervised learning problems are categorized into Regression and Classification problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. Commonly used algorithms: Linear Regression Logistics Regression Polynomial Regression Stepwise Regression Ridge Regression Lasso Regression ElasticNet Regression Support Vector Regression (SVR) In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. Commonly used algorithms: Linear Classifier (Logistic Regression & Naive Bayes) Support Vector Machines Decision Trees Random Forest Neural Networks Nearest Neighbor Example 1 : (a) Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. (b) We could turn this example into a classification problem by instead making our output about whether the house \"sells for more or less than the asking price.\" Here we are classifying the houses based on price into two discrete categories. Example 2 : (a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture (b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. Unsupervised Learning Unsupervised learning allows us to approach problems with little or no idea what our results should look like. With unsupervised learning there is no feedback based on the prediction results. We try to classify data into groups and extract new information hidden in the data We can derive structure: From data where we don't necessarily know the effect of the variables. By clustering the data based on relationships among the variables in the data. Example : Clustering : Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering : The \"Cocktail Party Algorithm\", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party). Commonly used algorithms: K-means Clustering Mean-Shift Clustering Density-Based Spatial Clustering of Applications(DBSCAN) Ex-Hierarchical Dimensionality Reduction (Principal Component Analysis) Ensemble learning In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone (eg: Random Forest).","title":"About"},{"location":"#what-is-machine-learning","text":"Arthur Samuel described it as: \"The field of study that gives computers the ability to learn without being explicitly programmed.\" This is an older, informal definition. Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\" ML systems learn how to combine input to produce useful predictions on never-before-seen data. Example : playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning Unsupervised learning","title":"What is Machine Learning?"},{"location":"#supervised-learning","text":"In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. We try to extrapolate labels for new data given labelled data we already have Supervised learning problems are categorized into Regression and Classification problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. Commonly used algorithms: Linear Regression Logistics Regression Polynomial Regression Stepwise Regression Ridge Regression Lasso Regression ElasticNet Regression Support Vector Regression (SVR) In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. Commonly used algorithms: Linear Classifier (Logistic Regression & Naive Bayes) Support Vector Machines Decision Trees Random Forest Neural Networks Nearest Neighbor Example 1 : (a) Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. (b) We could turn this example into a classification problem by instead making our output about whether the house \"sells for more or less than the asking price.\" Here we are classifying the houses based on price into two discrete categories. Example 2 : (a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture (b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign.","title":"Supervised Learning"},{"location":"#unsupervised-learning","text":"Unsupervised learning allows us to approach problems with little or no idea what our results should look like. With unsupervised learning there is no feedback based on the prediction results. We try to classify data into groups and extract new information hidden in the data We can derive structure: From data where we don't necessarily know the effect of the variables. By clustering the data based on relationships among the variables in the data. Example : Clustering : Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering : The \"Cocktail Party Algorithm\", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party). Commonly used algorithms: K-means Clustering Mean-Shift Clustering Density-Based Spatial Clustering of Applications(DBSCAN) Ex-Hierarchical Dimensionality Reduction (Principal Component Analysis)","title":"Unsupervised Learning"},{"location":"#ensemble-learning","text":"In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone (eg: Random Forest).","title":"Ensemble learning"},{"location":"algorithms/","text":"Supervised Learning Linear regression is a method for finding the straight line or hyperplane that best fits a set of points. Logistic Regression is a powerful statistical way of modeling a binomial outcome with one or more explanatory variables. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Examples: Credit Scoring Measuring the success rates of marketing campaigns Predicting the revenues of a certain product Is there going to be an earthquake on a particular day? Naive Bayes is based on applying Bayes\u2019 theorem with the \u201cnaive\u201d assumption of conditional independence between every pair of features given the value of the class variable. Examples: To mark an email as spam or not spam Classify a news article about technology, politics, or sports Check a piece of text expressing positive emotions, or negative emotions? Used for face recognition software Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side. Example: Finding mileage Document classification Image classification Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. Example: Automobile price prediction (Gradient Boosting Regression - which uses several weak decision trees) Random Forest is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Example: Predicting Diabetes Unsupervised Learning k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean. Density-based spatial clustering of applications with noise (DBSCAN) It is a density-based clustering non-parametric algorithm; given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components These are a versatile algorithms that can be used for any type of grouping. Some examples of use cases are: Behavioral segmentation: Segment by purchase history Segment by activities on application, website, or platform Define personas based on interests Create profiles based on activity monitoring Inventory categorization: Group inventory by sales activity Group inventory by manufacturing metrics Sorting sensor measurements: Detect activity types in motion sensors Group images Separate audio Identify groups in health monitoring Detecting bots or anomalies: Separate valid activity groups from bots Group valid activity to clean up outlier detection Something Else Reinforcement Learning , where we try to create a model that learns the rules of an environment to best maximize its return or reward.","title":"Definition"},{"location":"algorithms/#supervised-learning","text":"Linear regression is a method for finding the straight line or hyperplane that best fits a set of points. Logistic Regression is a powerful statistical way of modeling a binomial outcome with one or more explanatory variables. It measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Examples: Credit Scoring Measuring the success rates of marketing campaigns Predicting the revenues of a certain product Is there going to be an earthquake on a particular day? Naive Bayes is based on applying Bayes\u2019 theorem with the \u201cnaive\u201d assumption of conditional independence between every pair of features given the value of the class variable. Examples: To mark an email as spam or not spam Classify a news article about technology, politics, or sports Check a piece of text expressing positive emotions, or negative emotions? Used for face recognition software Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. In two dimentional space this hyperplane is a line dividing a plane in two parts where in each class lay in either side. Example: Finding mileage Document classification Image classification Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. Example: Automobile price prediction (Gradient Boosting Regression - which uses several weak decision trees) Random Forest is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Example: Predicting Diabetes","title":"Supervised Learning"},{"location":"algorithms/#unsupervised-learning","text":"k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean. Density-based spatial clustering of applications with noise (DBSCAN) It is a density-based clustering non-parametric algorithm; given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). Principal Component Analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components These are a versatile algorithms that can be used for any type of grouping. Some examples of use cases are: Behavioral segmentation: Segment by purchase history Segment by activities on application, website, or platform Define personas based on interests Create profiles based on activity monitoring Inventory categorization: Group inventory by sales activity Group inventory by manufacturing metrics Sorting sensor measurements: Detect activity types in motion sensors Group images Separate audio Identify groups in health monitoring Detecting bots or anomalies: Separate valid activity groups from bots Group valid activity to clean up outlier detection","title":"Unsupervised Learning"},{"location":"algorithms/#something-else","text":"Reinforcement Learning , where we try to create a model that learns the rules of an environment to best maximize its return or reward.","title":"Something Else"},{"location":"applications/","text":"Machine Learning creates a function that maps an input to an output. With deep learning, we can use a wide variety of data as input into this function, including tabular data, text, images, audio, and video. In addition, deep learning can map these inputs to a variety of outputs, including once again, tabular data, text, images, audio, and video. We're going to cover a few of the key deep learning applications that currently exist today, and some future applications that are just around the corner. Tables Let's start simple by looking at applications that use tabular data as both input and output. Tabular data are categorical and numeric values stored in columns and rows of the table. There are roughly four general categories of tasks that we can perform on tabular data with deep learning. Classification is where we attempt to make a decision or a prediction involving two or more categories or outcomes. For example, deciding whether to accept or reject a loan based on data from a customer's financial history. Regression is where we attempt to predict a numeric outcome based on one or more input variables. For example, trying to predict the sale price of a house based on the features of the house compared to the sale price of similar houses. Clustering is where we attempt to group similar objects together based on similarities in their data. For example, grouping customers into marketing segments based on their income, age, gender, number of children, etc. Anomaly Detection is where we find observations in the data that are different from the normal data. For example, detecting an unusual spike in the number of negative comments about a product that we've just released. While all four of these tasks can be performed on tabular data using deep neural networks, oftentimes deep learning is overkill for these types of tasks. This is typically the case when the tabular dataset is small, or the function we are attempting to model is relatively simple. These types of problems are generally solved more effectively using traditional machine learning tools, for example,decision tree classifiers, support vector machines, k-means clustering, or shallow, rather than deep neural networks. However, there are cases where the tabular datasets are large enough, and the function that we are attempting to model is complex enough that a deep neural network makes sense. For example, Stanford University announced that it had created a deep neural network to predict whether patients admitted to a hospital will die within the next year or not. The deep neural network was able to predict patient mortality with approximately 90% accuracy. This training algorithm used over 13,000 columns and over 220,000 rows of tabular data as input in order to reach this level of prediction accuracy. Text Now let's learn about deep learning applications for textual data; that is, bodies of text contained in documents. With deep learning, we can map the text and the document as an input to a variety of outputs. Examples : we can perform document classification . This is where we attempt to predict which category a document belongs to. i.e, predicting whether the topic of a news article is technology, sports, or entertainment. Natural language processing has also received tremendous benefits from deep learning as well. For example, deep neural networks can now understand the grammar, syntax, and meaning of sentences. Sentiment analysis is where we take a body of text as input, and determine the author's emotions behind the words. In the example below, we can see words and phrases that either have a positive sentiment in blue, neutral sentiment in gray, or a negative sentiment in red. We can also use deep learning to generate text as an output from a variety of inputs as well. For example, in the last module, we saw how recurrent neural networks can be used to predict the next letter someone is about to type based on the previous letters that they've already typed. However, we can also use recurrent neural networks to predict which word someone is likely to type based on all of the other words that they've previously typed. In addition, we can also use recurrent neural networks for language translation . This is where we translate words and phrases from one language into another language. You may have noticed how much better software based language translation has gotten in recent years. This is all thanks to advances in deep recurrent neural networks. We can train a recurrent neural network to generate headlines and summaries for bodies of text based on the content of the document. The computer generated headlines you see here are almost indistinguishable from the headlines that a human would create to summarize a story. Images With deep learning, we can map images as an input to a variety of outputs. For example: we can perform tasks like object recognition where we detect and provide labels for objects in an image. Gender classification, where we determine the gender of a subject in an image. Age regression, where we predict how old a person is in a photo. Emotion detection, where we predict the emotional state portrayed on a person's face. We can also perform more advanced image analysis tasks by combining a convolutional neural network with a deconvolutional neural network, an architecture known as a convolutional encoder decoder . This allows us to perform tasks like pixel wise image segmentation, where we extract pixels corresponding to specific objects in an image. For example, all of the pixels of the car in the center of this image have been color coded yellow. We can also combine a CNN and an RNN to perform image captioning . Image captioning is where we generate a description of what is happening in an image. As you can see from these three examples, the deep learning algorithm is able to provide a caption to each image that is almost indistinguishable from the caption a human would provide. However, we can also use deep learning to generate images as an output using a variety of different types of input. For example, super resolution convolutional neural networks have been applied to images to attempt to enhance their image resolution. As we can see, given an 8x8 array of pixels, the CNN is able to produce a 32x32 image that closely approximates the true image. We can also use generative adversarial networks to clean up the noise in an image as well. In fact, entire sections of this image can be missing, and the GAN will fill in the missing pixels, given the information surrounding the missing section. We can also use generative adversarial networks to modify existing images with new predictions. For example, we can take an image of yours truly and use a GAN to generate a prediction of what I'll look like in 20 years. In fact, this deep learning application is so good that it tricked the age detection algorithms into thinking that I was exactly 20 years older. We can also use deep learning to generate entirely new images from scratch. And how about these fake celebrities? Each of these images was created by a generative adversarial network. They may feel like real celebrities since the GAN was trained using more than 200,000 high-resolution images of real celebrities; however, not a single one of these synthetic celebrities is a real person. (Working) Finally, we're rapidly nearing a point in time where we can synthesize new images based on a description of what we want the image to look like. For example, all of these images were generated by a generative adversarial network using the descriptions above. It won't be long before we can just tell a computer what kind of image we need for our document or presentation, and it will synthesize an entirely new image to match our description. Audio With deep learning, we can map audio as an input to a wide variety of outputs. For example, we can use combinations of CNNs and RNNs to classify the source of a sound. This allows computers to recognize the song that you're listening to based on the music it's hearing. It also allows computers to recognize animals, vehicles, and environmental noises by sound alone. In addition, we can also use combinations of CNNs and RNNs to perform speech to text translation at near human level accuracy. If you've noticed how much better your smart phone has gotten at interpreting your commands in the past few years, once again, you can thank deep learning for the recent improvements. We can also use combinations of CNN and RNN encoder/decoder networks to perform real-time speech translation. For example, I can speak a sentence in one language, and in near real-time, the listener will hear what I said in their native language. But we can also use deep learning to generate audio as an output, given a variety of inputs. For example, using a type of deep neural network architecture known as a dilated causal convolutional neural network, we can have deep learning speech synthesis that sounds almost indistinguishable from actual human speech. Finally, here's an experimental application that's currently in development by Princeton University and Adobe. It allows you to feed in your audio recordings, it converts your audio into a transcript, and then it allows you to edit the text just like a text editor. Then after you've made your changes to the text, it synthesizes new audio that sounds almost identical to your own voice. While this specific application might be a few years away yet. Video With deep learning, we can map video as an input to a variety of types of outputs. For example, Tasks like object detection, where we classify an object as it's moving from frame to frame; facial recognition, where we recognize a person's face in a moving video; and outcome prediction, where we analyze a few frames of vide to attempt to predict what will happen next. Plus, this is also leading to entirely new applications like real-time sign language translation and computer-based lip reading. In fact, real-time sign language translation is rapidly approaching human level proficiency, and Google's LipNet is currently better than the average human lip reader. However, even more impressive is that we can now use deep learning to generate video as an output from a variety of inputs. For example, using a combination of convolutional encoder/decoder networks, we can now teach a computer to automatically colorize black and white videos. In addition, machines are also being taught to restore old or damaged films as well. And check this out. To help families refinance their homes. To invest in things like high-tech manufacturing, clean energy, and the infrastructure that creates good new jobs. You can see why it's so important that people understand the potential applications for deep learning before someone tries to use deep learning to deceive others for nefarious purposes. Future Finally, let's look at other future deep learning applications beyond the basic input to output mappings that we've already seen. It's important to note that what we've seen so far is just the beginning of deep learning technologies. Deep learning can be applied to a variety of other inputs, and produce a variety of other outputs. Plus, we can combine multiple types of inputs and produce multiple types of outputs as well. This leads to a whole new realm of possible applications for deep learning in the future. For example, self-driving cars connect a variety of sensor inputs with a set of vehicle control outputs to drive an automobile without any human intervention. This same deep learning technology can also be applied to other types of vehicles like semis, buses, boats, airplanes and drones as well.","title":"Applications"},{"location":"applications/#tables","text":"Let's start simple by looking at applications that use tabular data as both input and output. Tabular data are categorical and numeric values stored in columns and rows of the table. There are roughly four general categories of tasks that we can perform on tabular data with deep learning. Classification is where we attempt to make a decision or a prediction involving two or more categories or outcomes. For example, deciding whether to accept or reject a loan based on data from a customer's financial history. Regression is where we attempt to predict a numeric outcome based on one or more input variables. For example, trying to predict the sale price of a house based on the features of the house compared to the sale price of similar houses. Clustering is where we attempt to group similar objects together based on similarities in their data. For example, grouping customers into marketing segments based on their income, age, gender, number of children, etc. Anomaly Detection is where we find observations in the data that are different from the normal data. For example, detecting an unusual spike in the number of negative comments about a product that we've just released. While all four of these tasks can be performed on tabular data using deep neural networks, oftentimes deep learning is overkill for these types of tasks. This is typically the case when the tabular dataset is small, or the function we are attempting to model is relatively simple. These types of problems are generally solved more effectively using traditional machine learning tools, for example,decision tree classifiers, support vector machines, k-means clustering, or shallow, rather than deep neural networks. However, there are cases where the tabular datasets are large enough, and the function that we are attempting to model is complex enough that a deep neural network makes sense. For example, Stanford University announced that it had created a deep neural network to predict whether patients admitted to a hospital will die within the next year or not. The deep neural network was able to predict patient mortality with approximately 90% accuracy. This training algorithm used over 13,000 columns and over 220,000 rows of tabular data as input in order to reach this level of prediction accuracy.","title":"Tables"},{"location":"applications/#text","text":"Now let's learn about deep learning applications for textual data; that is, bodies of text contained in documents. With deep learning, we can map the text and the document as an input to a variety of outputs. Examples : we can perform document classification . This is where we attempt to predict which category a document belongs to. i.e, predicting whether the topic of a news article is technology, sports, or entertainment. Natural language processing has also received tremendous benefits from deep learning as well. For example, deep neural networks can now understand the grammar, syntax, and meaning of sentences. Sentiment analysis is where we take a body of text as input, and determine the author's emotions behind the words. In the example below, we can see words and phrases that either have a positive sentiment in blue, neutral sentiment in gray, or a negative sentiment in red. We can also use deep learning to generate text as an output from a variety of inputs as well. For example, in the last module, we saw how recurrent neural networks can be used to predict the next letter someone is about to type based on the previous letters that they've already typed. However, we can also use recurrent neural networks to predict which word someone is likely to type based on all of the other words that they've previously typed. In addition, we can also use recurrent neural networks for language translation . This is where we translate words and phrases from one language into another language. You may have noticed how much better software based language translation has gotten in recent years. This is all thanks to advances in deep recurrent neural networks. We can train a recurrent neural network to generate headlines and summaries for bodies of text based on the content of the document. The computer generated headlines you see here are almost indistinguishable from the headlines that a human would create to summarize a story.","title":"Text"},{"location":"applications/#images","text":"With deep learning, we can map images as an input to a variety of outputs. For example: we can perform tasks like object recognition where we detect and provide labels for objects in an image. Gender classification, where we determine the gender of a subject in an image. Age regression, where we predict how old a person is in a photo. Emotion detection, where we predict the emotional state portrayed on a person's face. We can also perform more advanced image analysis tasks by combining a convolutional neural network with a deconvolutional neural network, an architecture known as a convolutional encoder decoder . This allows us to perform tasks like pixel wise image segmentation, where we extract pixels corresponding to specific objects in an image. For example, all of the pixels of the car in the center of this image have been color coded yellow. We can also combine a CNN and an RNN to perform image captioning . Image captioning is where we generate a description of what is happening in an image. As you can see from these three examples, the deep learning algorithm is able to provide a caption to each image that is almost indistinguishable from the caption a human would provide. However, we can also use deep learning to generate images as an output using a variety of different types of input. For example, super resolution convolutional neural networks have been applied to images to attempt to enhance their image resolution. As we can see, given an 8x8 array of pixels, the CNN is able to produce a 32x32 image that closely approximates the true image. We can also use generative adversarial networks to clean up the noise in an image as well. In fact, entire sections of this image can be missing, and the GAN will fill in the missing pixels, given the information surrounding the missing section. We can also use generative adversarial networks to modify existing images with new predictions. For example, we can take an image of yours truly and use a GAN to generate a prediction of what I'll look like in 20 years. In fact, this deep learning application is so good that it tricked the age detection algorithms into thinking that I was exactly 20 years older. We can also use deep learning to generate entirely new images from scratch. And how about these fake celebrities? Each of these images was created by a generative adversarial network. They may feel like real celebrities since the GAN was trained using more than 200,000 high-resolution images of real celebrities; however, not a single one of these synthetic celebrities is a real person. (Working) Finally, we're rapidly nearing a point in time where we can synthesize new images based on a description of what we want the image to look like. For example, all of these images were generated by a generative adversarial network using the descriptions above. It won't be long before we can just tell a computer what kind of image we need for our document or presentation, and it will synthesize an entirely new image to match our description.","title":"Images"},{"location":"applications/#audio","text":"With deep learning, we can map audio as an input to a wide variety of outputs. For example, we can use combinations of CNNs and RNNs to classify the source of a sound. This allows computers to recognize the song that you're listening to based on the music it's hearing. It also allows computers to recognize animals, vehicles, and environmental noises by sound alone. In addition, we can also use combinations of CNNs and RNNs to perform speech to text translation at near human level accuracy. If you've noticed how much better your smart phone has gotten at interpreting your commands in the past few years, once again, you can thank deep learning for the recent improvements. We can also use combinations of CNN and RNN encoder/decoder networks to perform real-time speech translation. For example, I can speak a sentence in one language, and in near real-time, the listener will hear what I said in their native language. But we can also use deep learning to generate audio as an output, given a variety of inputs. For example, using a type of deep neural network architecture known as a dilated causal convolutional neural network, we can have deep learning speech synthesis that sounds almost indistinguishable from actual human speech. Finally, here's an experimental application that's currently in development by Princeton University and Adobe. It allows you to feed in your audio recordings, it converts your audio into a transcript, and then it allows you to edit the text just like a text editor. Then after you've made your changes to the text, it synthesizes new audio that sounds almost identical to your own voice. While this specific application might be a few years away yet.","title":"Audio"},{"location":"applications/#video","text":"With deep learning, we can map video as an input to a variety of types of outputs. For example, Tasks like object detection, where we classify an object as it's moving from frame to frame; facial recognition, where we recognize a person's face in a moving video; and outcome prediction, where we analyze a few frames of vide to attempt to predict what will happen next. Plus, this is also leading to entirely new applications like real-time sign language translation and computer-based lip reading. In fact, real-time sign language translation is rapidly approaching human level proficiency, and Google's LipNet is currently better than the average human lip reader. However, even more impressive is that we can now use deep learning to generate video as an output from a variety of inputs. For example, using a combination of convolutional encoder/decoder networks, we can now teach a computer to automatically colorize black and white videos. In addition, machines are also being taught to restore old or damaged films as well. And check this out. To help families refinance their homes. To invest in things like high-tech manufacturing, clean energy, and the infrastructure that creates good new jobs. You can see why it's so important that people understand the potential applications for deep learning before someone tries to use deep learning to deceive others for nefarious purposes.","title":"Video"},{"location":"applications/#future","text":"Finally, let's look at other future deep learning applications beyond the basic input to output mappings that we've already seen. It's important to note that what we've seen so far is just the beginning of deep learning technologies. Deep learning can be applied to a variety of other inputs, and produce a variety of other outputs. Plus, we can combine multiple types of inputs and produce multiple types of outputs as well. This leads to a whole new realm of possible applications for deep learning in the future. For example, self-driving cars connect a variety of sensor inputs with a set of vehicle control outputs to drive an automobile without any human intervention. This same deep learning technology can also be applied to other types of vehicles like semis, buses, boats, airplanes and drones as well.","title":"Future"},{"location":"dap/","text":"This process will help you understand, explore and use your data intelligently so that you make the most of the information you're given. Five steps: Question Wrangle Explore Draw conclusions Communicate. Question The data analysis process always starts with asking questions. Sometimes, you're already given a data set and glance over it to figure out good questions to ask. Other times, your questions come first, which will determine what kinds of data you'll gather later. In both cases, you should be thinking: what am I trying to find out? Is there a problem I'm trying to solve? Example: What are the characteristics of students who pass their projects? How can I better stock my store with products people want to buy? In the real world, you often deal with multiple sets of massive amounts of data, all in different forms. The right questions can really help you focus on relevant parts of your data and direct your analysis towards meaningful insights. Wrangle Once you have your questions, you'll need to wrangle your data to help you answer them. By that, I mean making sure you have all the data you need in great quality. There are three parts to this step: You gather your data. If you are already given that data, then all you need to do is open it, like importing it into a Jupyter notebook. If you weren't provided data, you need think carefully about what data would be most helpful in answering your questions and then collect them from all the sources available. You assess your data to identify any problems in your data's quality or structure. You clean your data. This often involves modifying, replacing, or moving data to ensure that your data set is as high quality and well-structured as possible. This wrangling step is all about getting the data you need in a form that you can work with. Explore Exploring involves finding patterns in your data, visualizing relationships in your data and just building intuition about what you're working with. After exploring, you can do things like remove outliers and create new and more descriptive features from existing data, also known as feature engineering . Many times modifying and engineer your data properly and even creatively can significantly increase the quality of your analysis. As you become more familiar with your data in this EDA step, you'll often revisit previous steps. Example : you might discover new problems in your data and go back to wrangle them. Or you might discover exciting, unexpected patterns and decide to refine your questions. The data analysis process isn't always linear. This exploratory step in particular is very intertwined with the rest of the process. It's usually where you discover and learn the most about your data. Conclusions After you've done your exploratory data analysis, you want to draw conclusions or even make predictions. Example : Predicting which students will fail a project so you can reach out to those students Or predicting which products are most likely to sell so you can start your store appropriately. Communicate Finally, you need to communicate your results to others. This is one of the most important skills you can develop. Your analysis is only as valuable as your ability to communicate it. You often need to justify and convey meaning in the insights you found Or if your end goal is to build a system, like a movie recommender or a news feed ranking algorithm, you usually share what you've built, explain how you reach design decisions and report how well it performs. You can communicate results in many ways: Reports Slide Decks Blog Posts Emails Presentations","title":"Data Analysis Process"},{"location":"dap/#question","text":"The data analysis process always starts with asking questions. Sometimes, you're already given a data set and glance over it to figure out good questions to ask. Other times, your questions come first, which will determine what kinds of data you'll gather later. In both cases, you should be thinking: what am I trying to find out? Is there a problem I'm trying to solve? Example: What are the characteristics of students who pass their projects? How can I better stock my store with products people want to buy? In the real world, you often deal with multiple sets of massive amounts of data, all in different forms. The right questions can really help you focus on relevant parts of your data and direct your analysis towards meaningful insights.","title":"Question"},{"location":"dap/#wrangle","text":"Once you have your questions, you'll need to wrangle your data to help you answer them. By that, I mean making sure you have all the data you need in great quality. There are three parts to this step: You gather your data. If you are already given that data, then all you need to do is open it, like importing it into a Jupyter notebook. If you weren't provided data, you need think carefully about what data would be most helpful in answering your questions and then collect them from all the sources available. You assess your data to identify any problems in your data's quality or structure. You clean your data. This often involves modifying, replacing, or moving data to ensure that your data set is as high quality and well-structured as possible. This wrangling step is all about getting the data you need in a form that you can work with.","title":"Wrangle"},{"location":"dap/#explore","text":"Exploring involves finding patterns in your data, visualizing relationships in your data and just building intuition about what you're working with. After exploring, you can do things like remove outliers and create new and more descriptive features from existing data, also known as feature engineering . Many times modifying and engineer your data properly and even creatively can significantly increase the quality of your analysis. As you become more familiar with your data in this EDA step, you'll often revisit previous steps. Example : you might discover new problems in your data and go back to wrangle them. Or you might discover exciting, unexpected patterns and decide to refine your questions. The data analysis process isn't always linear. This exploratory step in particular is very intertwined with the rest of the process. It's usually where you discover and learn the most about your data.","title":"Explore"},{"location":"dap/#conclusions","text":"After you've done your exploratory data analysis, you want to draw conclusions or even make predictions. Example : Predicting which students will fail a project so you can reach out to those students Or predicting which products are most likely to sell so you can start your store appropriately.","title":"Conclusions"},{"location":"dap/#communicate","text":"Finally, you need to communicate your results to others. This is one of the most important skills you can develop. Your analysis is only as valuable as your ability to communicate it. You often need to justify and convey meaning in the insights you found Or if your end goal is to build a system, like a movie recommender or a news feed ranking algorithm, you usually share what you've built, explain how you reach design decisions and report how well it performs. You can communicate results in many ways: Reports Slide Decks Blog Posts Emails Presentations","title":"Communicate"},{"location":"deep_learning/","text":"Deep Learning Deep Learning is a form of artificial intelligence that uses a type of machine learning called an artificial neural network with multiple hidden layers that learns hierarchical representations of the underlying data in order to make predictions given new data. Deep Learning attempts to model high-level abstractions about data using networks of graphs. It is focused on learning representations in data. Additionally, modeling high-level abstractions about data is very similar to artificial intelligence \u2014 the idea that knowledge can be represented and acted upon intelligently. Artificial Intelligence AI is a field of computer science that attempts to create machines that act rationally in response to their environment. Explicit Programming Encoding Domain Knowledge Statistical Patterns Detection Machine Learning ML is a type of artificial intelligence where we teach machines how to solve problems without explicitly programming then to do so. Artificial Neural Network It is a machine learning algorihtm based on a very crude approximation of biological neural network in a brain. If we connect a series of artificial neurons in a network, we get an artificial neural network or neural network. Forward Propagation: we use the network with its current parameters to compute a prediction for each example in our training dataset. We use the known correct answer that a human provided to determine if the network made a correct prediction or not. An incorrected prediction, which we refer to as a prediction error, will be used to teach the network to change the weights of its connections to avoid making prediction errors in the future. Backward Propagation: we use the prediction error that we computed in the last step to properly update the weights of the connections between each neuron to help the network make better future prediction. We use a technique called gradient descent to help us decide whether to increase or decrease each individual connection's weights, Training Rate is used to determine how much to increase or decrease the weights during each training step. We repeat this process for each training sample in the training dataset, and then we repeat the whole many times until the weights of the network become stable. Deep Neural Networks It is a neural network with more than one hidden layer. Techniques Which allow deep learning to solve a variety of problems: Fully Connected Networks Convolutional Networks Recurrent Networks Generative Adversarial Networks Deep Reinforcement Learning Fully Connected Neural Networks By fully connected, we mean that each neuron in the preceding layer is connected to every neuron in the subsequent layer. By feedforward, we mean that neurons in any preceding layer are only ever connected to the neurons in a subsequent layer. That is, there are no cycles or loops in the connections of the graph of neurons. As we mentioned in the previous module, each neuron in a neural network contains an activation function that changes the output of a neuron given its input. We have several types of activation functions that can change this input to output relationship to make a neuron behave in a variety of ways. Some of the most well-known activation functions: linear function , straight line that essentially multiplies the input by a constant value sigmoid function , s-shaped curve ranging from 0 to 1 hyperbolic tangent or tanH function , s-shaped curve ranging from -1 to +1 rectified linear unit or ReLU function , a piecewise function that outputs a 0 if the input is less than a certain value, or linear multiple if the input is greater than a certain value. The last three activation functions we refer to as non-linear functions because the output is not a linear multiple of the input. Non-linearity is what allows deep neural networks to model complex functions. We can create networks with various inputs, various outputs, various hidden layers, various neurons per hidden layer, and a variety of activation functions. These numerous combinations allow us to create a variety of powerful deep neural networks that can solve a wide array of problems. The more neurons we add to each hidden layer, the wider the network becomes. In addition, the more hidden layers we add, the deeper the network becomes. However, each neuron we add increases the complexity and thus the processing power necessary to train a neural network. This increase in complexity isn't linear in the number of neurons we add, which leads to an explosion in complexity and training time for large neural networks. As a result, there are certain non-fully connected neural network architectures called sparse neural networks that allow us to create deep neural networks without paying the high cost of a large fully connected network. Convolutional Neural Networks(CNN) CNN is a type of deep neural network architecture designed for specific tasks like image classification. CNNs were inspired by the organization of neurons in the visual cortex of the animal brain. As a result, they provide some very interesting features that are useful for processing certain types of data; like images, audio, and video. A CNN is composed of an input layer . However, for basic image processing, this input is typically a two-dimensional array of neurons which correspond to the pixels of an image. So, we'll represent this layer visually as a square instead of a set of circles. A CNN also contains an output layer which is typically a one-dimensional set of output neurons; one neuron for each category of image being classified. So, we'll represent this as a thick, solid line. A CNN also contains one or more hidden layers ; however, unlike a fully connected neural network, CNNs use a combination of sparsely connected convolution layers , which perform image processing on their inputs. In addition, they contain down sampling layers called pooling layers to further reduce the number of neurons necessary in subsequent layers of the network. CNNs typically contain one or more fully connected layers to connect our pooling layer to our output layer. Convolution is a technique that allows us to extract visual features from an image in small chunks. Each neuron in a convolution layer is responsible for a small cluster of neurons in the preceding layer. The bounding box that determines the cluster of neurons is called a filter, also known as a kernel . Conceptually, you can think of a filter moving across the image and performing a mathematical operation on individual regions of the image. It then sends the result to the corresponding neuron in the convolution layer. Filters mathematically modify the input of a convolution to help it detect certain types of features in the image. They can return the unmodified image, blur the image, sharpen the image, detect edges, and more. This is done by multiplying the original image values by a convolution matrix like the four matrices shown. Filters help a CNN detect certain features in an image by performing these transformations. Pooling , also known as subsampling or down sampling, is the next step in a convolutional neural network. Pooling reduces the number of neurons in the previous convolution layer while still retaining the most important information. There are different types of pooling that can be performed. For example, taking the average of each input neuron, the sum of each neuron, or the maximum value. For example , we're performing what is called a 2x2 max pool with a stride of two. When we put all these techniques together, we get an architecture for a deep neural network quite different from our fully connected neural network. First, we take an input image, which is a two-dimensional matrix, typically with three color channels. Next, we use a convolution layer with multiple filters to create a two-dimensional feature matrix as output for each filter. Then, we pool the results to produce a down sample feature matrix for each filter in the convolution layer. Next, we typically repeat the convolution and pooling steps multiple times using previous features as input. Then, we add a few fully connected hidden layers to help classify the image, and finally, we produce our classification prediction in the output layer. We can also reverse this architecture to create what is known as a deconvolutional neural network . These networks perform the inverse of a convolutional network. Rather than taking an image and converting it into a prediction value, these networks take an input value and attempt to produce an image instead. CNN work well for a variety of tasks including image recognition, image processing, image segmentation, video analysis, and natural language processing Recurrent Neural Networks All of the neural networks we've seen so far have been feedforward neural networks. They are called this because data flows only from the input x through one or more hidden neurons, h, to the output y. However, we also have several types of neural network architectures that contain feedback loops. Unlike feedforward neural networks, the recurrent neural network, or RNN, can operate effectively on sequences of data with variable input length. In order to visualize how an RNN works, let's rotate the path through the RNN from its previous left to right orientation to a top to bottom orientation instead. We're just going to focus on a single path through the network from the input x, through the hidden neuron h, to the output neuron y. Now let's unfold this path through the neural network over time. If we imagine this RNN moving through time this first path represents a network in time step one. The hidden node h1 uses the input x1 to reduce output y1. This is exactly what we've already seen with basic feedforward neural networks. Now let's add a second time step. The hidden node at the current time step, h2, uses both the new input x2, and its state from the previous time step, h1, as input to make its new prediction, y2. This means that a recurrent neural network uses knowledge of its previous state as an input for its current prediction, and we can repeat this process for an arbitrary number of steps allowing the network to propagate information via its hidden state through time. This is essentially like giving a neural network a short-term memory . This feature makes RNNs very effective for working with sequences of data that occur over time. For example, time-series data, like changes in stock prices, a sequence of characters, like a stream of characters being typed into a mobile phone, and a sequence of words, like the stream of words contained in the news article. For example , imagine we're creating a recurrent neural network to predict the next letter a person is likely to type based on the previous letters they've already typed. The letter that a user just typed is quite important to predicting the next letter. However, all of the previous letters are also very important to this prediction as well. At the first time step, the user types the letter h, so our network might predict that the next letter is an i based on all of the previous training examples that included the word hi. At the next time step, the user types the letter e, so our network uses both the new letter e plus the state of the first hidden neuron in order to compute our next prediction r. The network predicts this because of the high frequency of occurrences of the word her in our training dataset. Adding the letter l might predict the word help, and adding another l would predict the letter o, which would match the word our user intended to type, which is hello. RNNs work well for applications that involve a sequence of data that changes over time. These applications include natural language processing, speech recognition, language translation, conversation modeling, image captioning, and visual Q&A. Generative Adversarial Networks The GAN is a combination of two deep learning neural networks: a Generator Network, and a Discriminator Network. The Generator Network produces synthetic data, and the Discriminator Network tries to detect if the data that it's seeing is real or synthetic. These two networks are adversaries in the sense that they're both competing to beat one another. The Generator is trying to produce synthetic data indistinguishable from real data, and the Discriminator is trying to become progressively better at detecting fake data. For example , imagine we want to create a neural network that generates synthetic images. First, we'd acquire a library of real-world images that we can use to provide real images for the image detector network. Next, we'd create an Image Generator network to produce synthetic images. This would typically be a deconvolutional neural network, which we discussed earlier in this module. Then we'd create an Image Detector network to detect real images versus fake images. This would typically be a convolutional neural network which we also discussed earlier in this module. At first, the generator would essentially create random noise as it learns how to create images that can fool the detector. In addition, the detector would only have roughly 50/50 accuracy when predicting real versus fake images. However, with each training iteration, the generator gets progressively better at generating real images, and the detector gets progressively better at detecting fake images. If you let these networks compete with one another for long enough, the generator begins producing fake images that approximate real images. Generative Adversarial Networks have gained quite a bit of popularity in recent years. Some of their applications include: image generation, image enhancement, text generation, speech synthesis new drug discovery, and more. Deep Reinforcement Learning Now let's discuss reinforcement learning: our final technique for creating deep neural networks that can solve a variety of problems. Reinforcement learning involves an agent interacting with an environment. The agent is trying to achieve a goal of some kind within the environment. The environment has state, which the agent can observe. The agent has actions that it can take, which modify the state of the environment, and the agent receives reward signals when it achieves a goal of some kind. The objective of the agent is to learn how to interact with its environment in such a way that allows it to achieve its goals. For example , an agent might be a car trying to get its passengers to their destination. The environment would be the world the car is driving in. This would include the road, other cars, pedestrians, and any obstacles on the road. The car can observe the state of its environment; for example, it's position, speed, and direction, the orientation of the road it's driving on, and the location of any obstacles in its path. The car has actions that it can perform to modify the state of the world. For example, the car can accelerate, decelerate, turn left, or turn right. This allows it to change its position relative to the objects in the world. The car would receive reward signals when it achieves a goal of some kind; for example, we could reward the car when it arrives safely at its destination, for each mile it stays on the road, and for each minute it drives at a safe speed. We could also penalize the car when it drives off the road, travels at unsafe speeds, or climbs with an obstacle. The objective for the car is to learn how to drive in this world in such a way that it arrives at its destination. Deep reinforcement learning is the application of reinforcement learning to train deep neural networks. Like our previous deep neural networks, we have an input layer, an output layer, and multiple hidden layers. However, our input is the state of the environment; for example, position, speed, and direction; our output is a series of a possible actions; for example, speed up, slow down, turn left, or turn right. In addition, we're feeding our rewards signal into the network so that we can learn to associate what actions produce positive results given a specific state of the environment. This deep neural network attempts to predict the expected future reward for each action, given the current state of the environment. It then chooses whichever action's predicted to have the highest potential future reward, and performs that action. Some examples of Deep Reinforcement Learning Applications are games, including board games like chess and Go, card games like poker, and 8-bit video games. Autonomous vehicles, like self-driving cars, and autonomous drones. Robotics, including teaching robots how to walk, and teaching robots how to perform manual tasks. Management tasks, including inventory management, resource allocation, and logistics; and financial tasks, including investment decisions, portfolio design, and asset pricing.","title":"Deep Learning"},{"location":"deep_learning/#deep-learning","text":"Deep Learning is a form of artificial intelligence that uses a type of machine learning called an artificial neural network with multiple hidden layers that learns hierarchical representations of the underlying data in order to make predictions given new data. Deep Learning attempts to model high-level abstractions about data using networks of graphs. It is focused on learning representations in data. Additionally, modeling high-level abstractions about data is very similar to artificial intelligence \u2014 the idea that knowledge can be represented and acted upon intelligently.","title":"Deep Learning"},{"location":"deep_learning/#artificial-intelligence","text":"AI is a field of computer science that attempts to create machines that act rationally in response to their environment. Explicit Programming Encoding Domain Knowledge Statistical Patterns Detection","title":"Artificial Intelligence"},{"location":"deep_learning/#machine-learning","text":"ML is a type of artificial intelligence where we teach machines how to solve problems without explicitly programming then to do so.","title":"Machine Learning"},{"location":"deep_learning/#artificial-neural-network","text":"It is a machine learning algorihtm based on a very crude approximation of biological neural network in a brain. If we connect a series of artificial neurons in a network, we get an artificial neural network or neural network. Forward Propagation: we use the network with its current parameters to compute a prediction for each example in our training dataset. We use the known correct answer that a human provided to determine if the network made a correct prediction or not. An incorrected prediction, which we refer to as a prediction error, will be used to teach the network to change the weights of its connections to avoid making prediction errors in the future. Backward Propagation: we use the prediction error that we computed in the last step to properly update the weights of the connections between each neuron to help the network make better future prediction. We use a technique called gradient descent to help us decide whether to increase or decrease each individual connection's weights, Training Rate is used to determine how much to increase or decrease the weights during each training step. We repeat this process for each training sample in the training dataset, and then we repeat the whole many times until the weights of the network become stable.","title":"Artificial Neural Network"},{"location":"deep_learning/#deep-neural-networks","text":"It is a neural network with more than one hidden layer.","title":"Deep Neural Networks"},{"location":"deep_learning/#techniques","text":"Which allow deep learning to solve a variety of problems: Fully Connected Networks Convolutional Networks Recurrent Networks Generative Adversarial Networks Deep Reinforcement Learning","title":"Techniques"},{"location":"deep_learning/#fully-connected-neural-networks","text":"By fully connected, we mean that each neuron in the preceding layer is connected to every neuron in the subsequent layer. By feedforward, we mean that neurons in any preceding layer are only ever connected to the neurons in a subsequent layer. That is, there are no cycles or loops in the connections of the graph of neurons. As we mentioned in the previous module, each neuron in a neural network contains an activation function that changes the output of a neuron given its input. We have several types of activation functions that can change this input to output relationship to make a neuron behave in a variety of ways. Some of the most well-known activation functions: linear function , straight line that essentially multiplies the input by a constant value sigmoid function , s-shaped curve ranging from 0 to 1 hyperbolic tangent or tanH function , s-shaped curve ranging from -1 to +1 rectified linear unit or ReLU function , a piecewise function that outputs a 0 if the input is less than a certain value, or linear multiple if the input is greater than a certain value. The last three activation functions we refer to as non-linear functions because the output is not a linear multiple of the input. Non-linearity is what allows deep neural networks to model complex functions. We can create networks with various inputs, various outputs, various hidden layers, various neurons per hidden layer, and a variety of activation functions. These numerous combinations allow us to create a variety of powerful deep neural networks that can solve a wide array of problems. The more neurons we add to each hidden layer, the wider the network becomes. In addition, the more hidden layers we add, the deeper the network becomes. However, each neuron we add increases the complexity and thus the processing power necessary to train a neural network. This increase in complexity isn't linear in the number of neurons we add, which leads to an explosion in complexity and training time for large neural networks. As a result, there are certain non-fully connected neural network architectures called sparse neural networks that allow us to create deep neural networks without paying the high cost of a large fully connected network.","title":"Fully Connected Neural Networks"},{"location":"deep_learning/#convolutional-neural-networkscnn","text":"CNN is a type of deep neural network architecture designed for specific tasks like image classification. CNNs were inspired by the organization of neurons in the visual cortex of the animal brain. As a result, they provide some very interesting features that are useful for processing certain types of data; like images, audio, and video. A CNN is composed of an input layer . However, for basic image processing, this input is typically a two-dimensional array of neurons which correspond to the pixels of an image. So, we'll represent this layer visually as a square instead of a set of circles. A CNN also contains an output layer which is typically a one-dimensional set of output neurons; one neuron for each category of image being classified. So, we'll represent this as a thick, solid line. A CNN also contains one or more hidden layers ; however, unlike a fully connected neural network, CNNs use a combination of sparsely connected convolution layers , which perform image processing on their inputs. In addition, they contain down sampling layers called pooling layers to further reduce the number of neurons necessary in subsequent layers of the network. CNNs typically contain one or more fully connected layers to connect our pooling layer to our output layer. Convolution is a technique that allows us to extract visual features from an image in small chunks. Each neuron in a convolution layer is responsible for a small cluster of neurons in the preceding layer. The bounding box that determines the cluster of neurons is called a filter, also known as a kernel . Conceptually, you can think of a filter moving across the image and performing a mathematical operation on individual regions of the image. It then sends the result to the corresponding neuron in the convolution layer. Filters mathematically modify the input of a convolution to help it detect certain types of features in the image. They can return the unmodified image, blur the image, sharpen the image, detect edges, and more. This is done by multiplying the original image values by a convolution matrix like the four matrices shown. Filters help a CNN detect certain features in an image by performing these transformations. Pooling , also known as subsampling or down sampling, is the next step in a convolutional neural network. Pooling reduces the number of neurons in the previous convolution layer while still retaining the most important information. There are different types of pooling that can be performed. For example, taking the average of each input neuron, the sum of each neuron, or the maximum value. For example , we're performing what is called a 2x2 max pool with a stride of two. When we put all these techniques together, we get an architecture for a deep neural network quite different from our fully connected neural network. First, we take an input image, which is a two-dimensional matrix, typically with three color channels. Next, we use a convolution layer with multiple filters to create a two-dimensional feature matrix as output for each filter. Then, we pool the results to produce a down sample feature matrix for each filter in the convolution layer. Next, we typically repeat the convolution and pooling steps multiple times using previous features as input. Then, we add a few fully connected hidden layers to help classify the image, and finally, we produce our classification prediction in the output layer. We can also reverse this architecture to create what is known as a deconvolutional neural network . These networks perform the inverse of a convolutional network. Rather than taking an image and converting it into a prediction value, these networks take an input value and attempt to produce an image instead. CNN work well for a variety of tasks including image recognition, image processing, image segmentation, video analysis, and natural language processing","title":"Convolutional Neural Networks(CNN)"},{"location":"deep_learning/#recurrent-neural-networks","text":"All of the neural networks we've seen so far have been feedforward neural networks. They are called this because data flows only from the input x through one or more hidden neurons, h, to the output y. However, we also have several types of neural network architectures that contain feedback loops. Unlike feedforward neural networks, the recurrent neural network, or RNN, can operate effectively on sequences of data with variable input length. In order to visualize how an RNN works, let's rotate the path through the RNN from its previous left to right orientation to a top to bottom orientation instead. We're just going to focus on a single path through the network from the input x, through the hidden neuron h, to the output neuron y. Now let's unfold this path through the neural network over time. If we imagine this RNN moving through time this first path represents a network in time step one. The hidden node h1 uses the input x1 to reduce output y1. This is exactly what we've already seen with basic feedforward neural networks. Now let's add a second time step. The hidden node at the current time step, h2, uses both the new input x2, and its state from the previous time step, h1, as input to make its new prediction, y2. This means that a recurrent neural network uses knowledge of its previous state as an input for its current prediction, and we can repeat this process for an arbitrary number of steps allowing the network to propagate information via its hidden state through time. This is essentially like giving a neural network a short-term memory . This feature makes RNNs very effective for working with sequences of data that occur over time. For example, time-series data, like changes in stock prices, a sequence of characters, like a stream of characters being typed into a mobile phone, and a sequence of words, like the stream of words contained in the news article. For example , imagine we're creating a recurrent neural network to predict the next letter a person is likely to type based on the previous letters they've already typed. The letter that a user just typed is quite important to predicting the next letter. However, all of the previous letters are also very important to this prediction as well. At the first time step, the user types the letter h, so our network might predict that the next letter is an i based on all of the previous training examples that included the word hi. At the next time step, the user types the letter e, so our network uses both the new letter e plus the state of the first hidden neuron in order to compute our next prediction r. The network predicts this because of the high frequency of occurrences of the word her in our training dataset. Adding the letter l might predict the word help, and adding another l would predict the letter o, which would match the word our user intended to type, which is hello. RNNs work well for applications that involve a sequence of data that changes over time. These applications include natural language processing, speech recognition, language translation, conversation modeling, image captioning, and visual Q&A.","title":"Recurrent Neural Networks"},{"location":"deep_learning/#generative-adversarial-networks","text":"The GAN is a combination of two deep learning neural networks: a Generator Network, and a Discriminator Network. The Generator Network produces synthetic data, and the Discriminator Network tries to detect if the data that it's seeing is real or synthetic. These two networks are adversaries in the sense that they're both competing to beat one another. The Generator is trying to produce synthetic data indistinguishable from real data, and the Discriminator is trying to become progressively better at detecting fake data. For example , imagine we want to create a neural network that generates synthetic images. First, we'd acquire a library of real-world images that we can use to provide real images for the image detector network. Next, we'd create an Image Generator network to produce synthetic images. This would typically be a deconvolutional neural network, which we discussed earlier in this module. Then we'd create an Image Detector network to detect real images versus fake images. This would typically be a convolutional neural network which we also discussed earlier in this module. At first, the generator would essentially create random noise as it learns how to create images that can fool the detector. In addition, the detector would only have roughly 50/50 accuracy when predicting real versus fake images. However, with each training iteration, the generator gets progressively better at generating real images, and the detector gets progressively better at detecting fake images. If you let these networks compete with one another for long enough, the generator begins producing fake images that approximate real images. Generative Adversarial Networks have gained quite a bit of popularity in recent years. Some of their applications include: image generation, image enhancement, text generation, speech synthesis new drug discovery, and more.","title":"Generative Adversarial Networks"},{"location":"deep_learning/#deep-reinforcement-learning","text":"Now let's discuss reinforcement learning: our final technique for creating deep neural networks that can solve a variety of problems. Reinforcement learning involves an agent interacting with an environment. The agent is trying to achieve a goal of some kind within the environment. The environment has state, which the agent can observe. The agent has actions that it can take, which modify the state of the environment, and the agent receives reward signals when it achieves a goal of some kind. The objective of the agent is to learn how to interact with its environment in such a way that allows it to achieve its goals. For example , an agent might be a car trying to get its passengers to their destination. The environment would be the world the car is driving in. This would include the road, other cars, pedestrians, and any obstacles on the road. The car can observe the state of its environment; for example, it's position, speed, and direction, the orientation of the road it's driving on, and the location of any obstacles in its path. The car has actions that it can perform to modify the state of the world. For example, the car can accelerate, decelerate, turn left, or turn right. This allows it to change its position relative to the objects in the world. The car would receive reward signals when it achieves a goal of some kind; for example, we could reward the car when it arrives safely at its destination, for each mile it stays on the road, and for each minute it drives at a safe speed. We could also penalize the car when it drives off the road, travels at unsafe speeds, or climbs with an obstacle. The objective for the car is to learn how to drive in this world in such a way that it arrives at its destination. Deep reinforcement learning is the application of reinforcement learning to train deep neural networks. Like our previous deep neural networks, we have an input layer, an output layer, and multiple hidden layers. However, our input is the state of the environment; for example, position, speed, and direction; our output is a series of a possible actions; for example, speed up, slow down, turn left, or turn right. In addition, we're feeding our rewards signal into the network so that we can learn to associate what actions produce positive results given a specific state of the environment. This deep neural network attempts to predict the expected future reward for each action, given the current state of the environment. It then chooses whichever action's predicted to have the highest potential future reward, and performs that action. Some examples of Deep Reinforcement Learning Applications are games, including board games like chess and Go, card games like poker, and 8-bit video games. Autonomous vehicles, like self-driving cars, and autonomous drones. Robotics, including teaching robots how to walk, and teaching robots how to perform manual tasks. Management tasks, including inventory management, resource allocation, and logistics; and financial tasks, including investment decisions, portfolio design, and asset pricing.","title":"Deep Reinforcement Learning"},{"location":"libraries/","text":"Libraries Numpy let's you perform mathematical functions on large multi dimensional arrays and matrices efficiently. Pandas is used for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. PyTorch provides a wide range of algorithms for deep learning and is used for applications such as natural language processing (based on Torch). Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano; runs seamlessly on CPU and GPU. Eli5 allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models. Matplotlib is a plotting library that can produce great visualizations often with very few lines of code. Scikit-learn is designed to work with NumPy, SciPy and Pandas, provides toolset for training and evaluation tasks: Data splitting Pre-processing Feature selection Model training Model tuning and offers common interface across algorithms XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI). LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency. Lower memory usage. Better accuracy. Support of parallel and GPU learning. Capable of handling large-scale data.","title":"Libraries"},{"location":"libraries/#libraries","text":"Numpy let's you perform mathematical functions on large multi dimensional arrays and matrices efficiently. Pandas is used for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. PyTorch provides a wide range of algorithms for deep learning and is used for applications such as natural language processing (based on Torch). Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano; runs seamlessly on CPU and GPU. Eli5 allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models. Matplotlib is a plotting library that can produce great visualizations often with very few lines of code. Scikit-learn is designed to work with NumPy, SciPy and Pandas, provides toolset for training and evaluation tasks: Data splitting Pre-processing Feature selection Model training Model tuning and offers common interface across algorithms XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. The same code runs on major distributed environment (Hadoop, SGE, MPI). LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency. Lower memory usage. Better accuracy. Support of parallel and GPU learning. Capable of handling large-scale data.","title":"Libraries"},{"location":"logistic_regression/","text":"","title":"Logistic Regression"},{"location":"math/","text":"Mean deviation refers to how far away every data point is from the average of those data points. Squared mean deviation simply squares this result. This is the square of the distance of every data point from the mean, and now we can finally calculate the variance of these data points. $$variance=\\frac{\\sum(x_i-\\overline{x})^2}{n}$$ Variance describe the concentration of data points around the mean, It is a measure of spread/variability of data. It is calculated as sum of the squares of the distances of every individual data point from the mean divided by the total number of data points. The estimate of the variance can be improved by tweaking the denominator of this function. This tweak is called the Bessel's Correction . So instead of using N for all of the data points, we'll simply use N-1 as the denominator. $$variance=\\frac{\\sum(x_i-\\overline{x})^2}{n-1}$$ Mean and variance succinctly summarize a set of numbers along with Standard deviation , which once again measures how much the numbers jump around. $$SD = \\sqrt{variance}$$ Mean Square Error (MSE) MSE is the average squared loss per example over the whole dataset. To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples: $$MSE = \\frac{1}{N} \\sum_{(x,y)\\in D} (y - prediction(x))^2$$ Standard Error(SE) of a statistic is the standard deviation of its sampling distribution or an estimate of that standard deviation. If the parameter or the statistic is the mean, it is called the standard error of the mean (SEM). $\\sigma$=Standard Deviation of population, n=size of sample $$SE = \\frac{\\sigma}{\\sqrt{n}}$$ Z score (Standard Score) Given an observed value x, the Z score finds the number of Standard deviations x is away from the mean. $$Z = \\frac{x-\\mu}{\\sigma}$$ T distribution The t-Test is best to use when we do not know the population standard deviation. Instead we use the sample standard deviation. The number of degrees of freedom(df) is the number of values that are free to vary (n-1). $$S=\\frac{\\sum(x_i-\\overline{x})^2}{n-1}$$ $$t = \\frac{\\overline{x}-\\mu}{SE}$$ T-tests are also great for testing two sample means (i.e. paired t-tests), we modify the formula to become: $$SD = \\sqrt{S_1^2 + S_2^2}$$ $$SE = \\sqrt{\\frac{S_1^2}{n1} + \\frac{S_2^2}{n2}}$$ $$t = \\frac{(\\overline{x}_2-\\overline{x}_1)-(\\mu_2-\\mu_1)}{\\frac{\\sqrt(s_1^2+s_2^2)}{n}}$$ Cohen's d It measures the effect size of the strength of a phenomenon. Cohen\u2019s d gives us the distance between means in standardized units. $\\overline{x} = \\overline{x_1} - \\overline{x_2}$ $$d = \\frac{\\overline{x}-\\mu}{S}$$ Margin of Error (ME) $$ME = t_{critical} * SE$$ Confidence Interval (CI) $$CI = \\overline{x} \\pm ME$$ Evaluation Metrics Positive Class In binary classification, the two possible classes are labeled as positive and negative. The positive outcome is the thing we're testing for. (Admittedly, we're simultaneously testing for both outcomes, but play along.) For example, the positive class in a medical test might be \"tumor.\" The positive class in an email classifier might be \"spam\". Negative Class In binary classification, one class is termed positive and the other is termed negative. The positive class is the thing we're looking for and the negative class is the other possibility. For example, the negative class in a medical test might be \"not tumor.\" The negative class in an email classifier might be \"not spam\". True Positive (TP) An example in which the model correctly predicted the positive class. For example, the model inferred that a particular email message was spam, and that email message really was spam. True Negative (TN) An example in which the model correctly predicted the negative class. For example, the model inferred that a particular email message was not spam, and that email message really was not spam. true positive rate (TPR) Synonym for recall. That is: True positive rate is the y-axis in an ROC curve. $$\\text{True Positive Rate} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}$$ False Negative (FN) An example in which the model mistakenly predicted the negative class. For example, the model inferred that a particular email message was not spam (the negative class), but that email message actually was spam. False Positive (FP) An example in which the model mistakenly predicted the positive class. For example, the model inferred that a particular email message was spam (the positive class), but that email message was actually not spam. false positive rate (FPR) The x-axis in an ROC curve. The false positive rate is defined as follows: $$\\text{False Positive Rate} = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}$$ ROC (receiver operating characteristic) Curve: A curve of true positive rate vs. false positive rate at different classification thresholds. Accuracy The fraction of predictions that a classification model got right. In multi-class classification, accuracy is defined as follows: $$\\text{Accuracy} = \\frac{\\text{Correct Predictions}} {\\text{Total Number Of Examples}}$$ In binary classification, accuracy has the following definition: $$\\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Number Of Examples}}$$ Precision A metric for classification models. Precision identifies the frequency with which a model was correct when predicting the positive class. That is: $$\\text{Precision} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Positives}}$$ Recall A metric for classification models that answers the following question: Out of all the possible positive labels, how many did the model correctly identify? That is: $$\\text{Recall} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}$$ In medical field it is common to use Sensitivity and Specificity, where Sensitivity is same as Recall while Specificity is as follows: $$\\text{Specificity} = \\frac{\\text{True Negatives}} {\\text{True Negatives} + \\text{False Positives}}$$ Now, sensitivity and specificity are the rows of this matrix. More specifically, if we label TP: Sick people that we correctly diagnosed as sick. TN: Healthy people that we correctly diagnosed as healthy. FP: Healthy people that we incorrectly diagnosed as sick. FN: Sick people that we incorrectly diagnosed as healthy.","title":"Math"},{"location":"math/#z-score-standard-score","text":"Given an observed value x, the Z score finds the number of Standard deviations x is away from the mean. $$Z = \\frac{x-\\mu}{\\sigma}$$","title":"Z score (Standard Score)"},{"location":"math/#t-distribution","text":"The t-Test is best to use when we do not know the population standard deviation. Instead we use the sample standard deviation. The number of degrees of freedom(df) is the number of values that are free to vary (n-1). $$S=\\frac{\\sum(x_i-\\overline{x})^2}{n-1}$$ $$t = \\frac{\\overline{x}-\\mu}{SE}$$ T-tests are also great for testing two sample means (i.e. paired t-tests), we modify the formula to become: $$SD = \\sqrt{S_1^2 + S_2^2}$$ $$SE = \\sqrt{\\frac{S_1^2}{n1} + \\frac{S_2^2}{n2}}$$ $$t = \\frac{(\\overline{x}_2-\\overline{x}_1)-(\\mu_2-\\mu_1)}{\\frac{\\sqrt(s_1^2+s_2^2)}{n}}$$","title":"T distribution"},{"location":"math/#cohens-d","text":"It measures the effect size of the strength of a phenomenon. Cohen\u2019s d gives us the distance between means in standardized units. $\\overline{x} = \\overline{x_1} - \\overline{x_2}$ $$d = \\frac{\\overline{x}-\\mu}{S}$$","title":"Cohen's d"},{"location":"math/#margin-of-error-me","text":"$$ME = t_{critical} * SE$$","title":"Margin of Error (ME)"},{"location":"math/#confidence-interval-ci","text":"$$CI = \\overline{x} \\pm ME$$","title":"Confidence Interval (CI)"},{"location":"math/#evaluation-metrics","text":"Positive Class In binary classification, the two possible classes are labeled as positive and negative. The positive outcome is the thing we're testing for. (Admittedly, we're simultaneously testing for both outcomes, but play along.) For example, the positive class in a medical test might be \"tumor.\" The positive class in an email classifier might be \"spam\". Negative Class In binary classification, one class is termed positive and the other is termed negative. The positive class is the thing we're looking for and the negative class is the other possibility. For example, the negative class in a medical test might be \"not tumor.\" The negative class in an email classifier might be \"not spam\". True Positive (TP) An example in which the model correctly predicted the positive class. For example, the model inferred that a particular email message was spam, and that email message really was spam. True Negative (TN) An example in which the model correctly predicted the negative class. For example, the model inferred that a particular email message was not spam, and that email message really was not spam. true positive rate (TPR) Synonym for recall. That is: True positive rate is the y-axis in an ROC curve. $$\\text{True Positive Rate} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}$$ False Negative (FN) An example in which the model mistakenly predicted the negative class. For example, the model inferred that a particular email message was not spam (the negative class), but that email message actually was spam. False Positive (FP) An example in which the model mistakenly predicted the positive class. For example, the model inferred that a particular email message was spam (the positive class), but that email message was actually not spam. false positive rate (FPR) The x-axis in an ROC curve. The false positive rate is defined as follows: $$\\text{False Positive Rate} = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}$$ ROC (receiver operating characteristic) Curve: A curve of true positive rate vs. false positive rate at different classification thresholds. Accuracy The fraction of predictions that a classification model got right. In multi-class classification, accuracy is defined as follows: $$\\text{Accuracy} = \\frac{\\text{Correct Predictions}} {\\text{Total Number Of Examples}}$$ In binary classification, accuracy has the following definition: $$\\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Number Of Examples}}$$ Precision A metric for classification models. Precision identifies the frequency with which a model was correct when predicting the positive class. That is: $$\\text{Precision} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Positives}}$$ Recall A metric for classification models that answers the following question: Out of all the possible positive labels, how many did the model correctly identify? That is: $$\\text{Recall} = \\frac{\\text{True Positives}} {\\text{True Positives} + \\text{False Negatives}}$$ In medical field it is common to use Sensitivity and Specificity, where Sensitivity is same as Recall while Specificity is as follows: $$\\text{Specificity} = \\frac{\\text{True Negatives}} {\\text{True Negatives} + \\text{False Positives}}$$ Now, sensitivity and specificity are the rows of this matrix. More specifically, if we label TP: Sick people that we correctly diagnosed as sick. TN: Healthy people that we correctly diagnosed as healthy. FP: Healthy people that we incorrectly diagnosed as sick. FN: Sick people that we incorrectly diagnosed as healthy.","title":"Evaluation Metrics"},{"location":"ml_workflow/","text":"An orchestrated and repeatable pattern which systematically transforms and processes information to create prediction solutions. Asking the right question Preparing data Selecting the algorithm Training the model Testing the model Solution Statement Use the Machine Learning Workflow to process and transform Pima Indian data to create a prediction model. This model must predict which peopel are likely to develop diabetes with 70% or greater accuracy Tidy Data Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column each observation is a row each type of observational unit is a table Selecting the algorithm We will use our problem knowledge to help us decide the algorithm to use. we will discuss - The role of the algorithm in machine learning process, select our initial algorithm by utilizing the requirements identified in the solution statement as a guide, and discuss at a high level the characteristics of some specific algorithms. Finally select one algorithm to be our initial algorithm, in machine learning we often cycle through the workflow. In our search to find the best solution, it is likely we will need to train and evaluate multiple algorithms. Let's review how the algorithm is involved in the process. When the training function (often named fit in scikit-learn) is called, the algorithm executes its logic and processes the training data. Using the algorithm's logic, the data in analyzed. This analysis evaluates the data with respect to mathematical model and logic associated with the algorithm. The algorithm uses the results of this analysis to adjust internal parameters to produce a model that has been trained to best fit the features in the training data and produce the associated class result. This best fit is defined by evaluating a function specific to the particular algorithm. The fit parameters are stored and the model is now said to be trained. Later, the trained model is called the prediction function (often named predict in scikit-learn). When this prediction function is called, real data is passed to the trained model. Using only the features in the data, the trained model uses its code and parameter values set during training to evaluate the data's features and predict the class result, diabetes or not for this new data. Decision factors to select our initial algorithm: We will use our solution statement and knowledge of the workflow to help guide us in the evaluation of these factors. what Learning Type they support the Result Type the algorithm predicts the Complexity of the algorithm whether the algorithm is Basic or Enhanced Each algorithm has a set of problems with which it works best. One way to divide them is to look at the type of Learning they support. Reading the statement, we see that our solution is about prediction. Prediction means supervised machine learning, so we can eliminate all algorithms that do not support it. Let's see how Result Type can help. Prediction results can be divided into two categories: Regression (Continuous values) Classification (Discrete values) Based on the Statment, the algorithm must support Binary classification. Since this is our initial algorithm, let's stick to the basic algorithms. Selecting Our Initial Algorithm Candidate Algorithms: Naive Bayes Logistic Regression Decision Tree More complex algoritms use these as building blocks. Naive Bayes Algorithm The Naive Bayes algorithm is based on Bayes' Theorem. This theorem calculates a probability of a diabetes by looking at the likelihood of diabetes based on previous data combined with probability of diabetes on nearby feature values. In other words, so how often does the person having high blood pressure correlate to diabetes? It makes the naive assumption that all of the features we pass in are independent of each other and equally impact the result. This assumption that every featuer is independent to the others allows for fast conversions and therefore requires a small amount of data to train. Logistic Regression Algorithm The Logistic Regression algorithm has a somewhat confusing name. In Statistics, Regression often implies continuous values. But Logistics Regression returns a binary result. The algorithm measures the relationship of each feature and weights them based on their impact on the result. The resultant value is mapped against a curve with two values, one and zero, which is equivalent to diabetes or no diabetes. Decision Tree Algorithm The Decision Tree algorithm can be nicely visualized. The algorithm uses a binary tree structure with each node making a decision based upon the values of the feature. At each node, the feature value causes us to go down one path or another. A lot of data may be required to find the value which defines taking one path or another. As we see decision trees have the advantage of having tools available to produce a picture of the tree. This makes it easy to follow along and visualize how the trained model works. Training the Model Letting specific data teach a machine learning algorithm to create a specific prediction model. Why retrain? Retraining will ensure that our model can take advantage of the new data to make better predictions. And also verify the algorithm can still create a high-performance model with the new data. We will compare our model prediction with actual prediction or actual labels that are associated with training data and use this as feeback to tweak our model parameters, this is the loss function or cost function and its primary purpose is to improve our model parameters and build stronger model. Performance Improvement Options Adjust current algorithm Get more data or improve data Improve training Switch algorithms","title":"Workflow with example"},{"location":"ml_workflow/#solution-statement","text":"Use the Machine Learning Workflow to process and transform Pima Indian data to create a prediction model. This model must predict which peopel are likely to develop diabetes with 70% or greater accuracy","title":"Solution Statement"},{"location":"ml_workflow/#tidy-data","text":"Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column each observation is a row each type of observational unit is a table","title":"Tidy Data"},{"location":"ml_workflow/#selecting-the-algorithm","text":"We will use our problem knowledge to help us decide the algorithm to use. we will discuss - The role of the algorithm in machine learning process, select our initial algorithm by utilizing the requirements identified in the solution statement as a guide, and discuss at a high level the characteristics of some specific algorithms. Finally select one algorithm to be our initial algorithm, in machine learning we often cycle through the workflow. In our search to find the best solution, it is likely we will need to train and evaluate multiple algorithms. Let's review how the algorithm is involved in the process. When the training function (often named fit in scikit-learn) is called, the algorithm executes its logic and processes the training data. Using the algorithm's logic, the data in analyzed. This analysis evaluates the data with respect to mathematical model and logic associated with the algorithm. The algorithm uses the results of this analysis to adjust internal parameters to produce a model that has been trained to best fit the features in the training data and produce the associated class result. This best fit is defined by evaluating a function specific to the particular algorithm. The fit parameters are stored and the model is now said to be trained. Later, the trained model is called the prediction function (often named predict in scikit-learn). When this prediction function is called, real data is passed to the trained model. Using only the features in the data, the trained model uses its code and parameter values set during training to evaluate the data's features and predict the class result, diabetes or not for this new data. Decision factors to select our initial algorithm: We will use our solution statement and knowledge of the workflow to help guide us in the evaluation of these factors. what Learning Type they support the Result Type the algorithm predicts the Complexity of the algorithm whether the algorithm is Basic or Enhanced Each algorithm has a set of problems with which it works best. One way to divide them is to look at the type of Learning they support. Reading the statement, we see that our solution is about prediction. Prediction means supervised machine learning, so we can eliminate all algorithms that do not support it. Let's see how Result Type can help. Prediction results can be divided into two categories: Regression (Continuous values) Classification (Discrete values) Based on the Statment, the algorithm must support Binary classification. Since this is our initial algorithm, let's stick to the basic algorithms.","title":"Selecting the algorithm"},{"location":"ml_workflow/#selecting-our-initial-algorithm","text":"Candidate Algorithms: Naive Bayes Logistic Regression Decision Tree More complex algoritms use these as building blocks.","title":"Selecting Our Initial Algorithm"},{"location":"ml_workflow/#naive-bayes-algorithm","text":"The Naive Bayes algorithm is based on Bayes' Theorem. This theorem calculates a probability of a diabetes by looking at the likelihood of diabetes based on previous data combined with probability of diabetes on nearby feature values. In other words, so how often does the person having high blood pressure correlate to diabetes? It makes the naive assumption that all of the features we pass in are independent of each other and equally impact the result. This assumption that every featuer is independent to the others allows for fast conversions and therefore requires a small amount of data to train.","title":"Naive Bayes Algorithm"},{"location":"ml_workflow/#logistic-regression-algorithm","text":"The Logistic Regression algorithm has a somewhat confusing name. In Statistics, Regression often implies continuous values. But Logistics Regression returns a binary result. The algorithm measures the relationship of each feature and weights them based on their impact on the result. The resultant value is mapped against a curve with two values, one and zero, which is equivalent to diabetes or no diabetes.","title":"Logistic Regression Algorithm"},{"location":"ml_workflow/#decision-tree-algorithm","text":"The Decision Tree algorithm can be nicely visualized. The algorithm uses a binary tree structure with each node making a decision based upon the values of the feature. At each node, the feature value causes us to go down one path or another. A lot of data may be required to find the value which defines taking one path or another. As we see decision trees have the advantage of having tools available to produce a picture of the tree. This makes it easy to follow along and visualize how the trained model works.","title":"Decision Tree Algorithm"},{"location":"ml_workflow/#training-the-model","text":"Letting specific data teach a machine learning algorithm to create a specific prediction model. Why retrain? Retraining will ensure that our model can take advantage of the new data to make better predictions. And also verify the algorithm can still create a high-performance model with the new data. We will compare our model prediction with actual prediction or actual labels that are associated with training data and use this as feeback to tweak our model parameters, this is the loss function or cost function and its primary purpose is to improve our model parameters and build stronger model. Performance Improvement Options Adjust current algorithm Get more data or improve data Improve training Switch algorithms","title":"Training the Model"},{"location":"source/","text":"DS & Model Report Playground NumPy Pandas DataFrame Stroop Effect Practice Problem Data Analysis Process Assessing Cleaning Plotting Conclusion Communicate Case Study Wine Rating Case Study Fuel Economy Fuel Economy - Conclusion Fuel Economy - Visuals Fuel Economy - Merging Data Investigate Dataset Titanic Movies ML Nanodegree Predict House Price Finding Donors Customer Segments Decision Tree Titanic Survival Exploration Naive Bayes Email Spam or Ham Random Forest & Logistic Regression Predict Diabetes Categorical and Numeric Data Text Feature Extraction Image Feature Extraction Lasso & Ridge Regression Vehicle Price SVR Mileage SVM Document Classification Image Classification Gradient Boost Regression / Decision Tree Automobile Price Mean Shift Clustering Titanic Survivor PCA Wine Rating NLTK Getting Started with NLTK Accessing Text Corpora and Lexical Resources Spark Getting Started with Spark 2 London Crime Data Soccer Data Miscellaneous Operations Introducing SparkSQL Airline Data Inferred And Explicit Schemas Windowing Functions Deep Learning Python Basics With Numpy Logistic Regression with a Neural Network mindset Gradient Descent XOR Network Student Admission(Keras) IMDB Review(Keras) Convolution Layer Dimension MNIST-Identify Digit","title":"Source"},{"location":"tensorflow/","text":"Tensor In TensorFlow, data isn\u2019t stored as integers, floats, or strings. These values are encapsulated in an object called a tensor. import tensorflow as tf # Create TensorFlow object called hello_constant hello_constant = tf.constant('Hello World!') with tf.Session() as sess: # Run the tf.constant operation in the session output = sess.run(hello_constant) print(output) Session TensorFlow\u2019s api is built around the idea of a computational graph, a way of visualizing a mathematical process. TensorFlow consists of the following two components: a graph protocol buffer a runtime that executes the (distributed) graph These two components are analogous to Python code and the Python interpreter. Just as the Python interpreter is implemented on multiple hardware platforms to run Python code, TensorFlow can run the graph on multiple hardware platforms, including CPU, GPU, and TPU A Quick Look at the tf.estimator API import tensorflow as tf # Set up a linear classifier. classifier = tf.estimator.LinearClassifier(feature_columns) # Train the model on some example data. classifier.train(input_fn=train_input_fn, steps=2000) # Use it to predict. predictions = classifier.predict(input_fn=predict_input_fn) Hyperparameters Steps , which is the total number of training iterations. One step calculates the loss from one batch and uses that value to modify the model's weights once. Batch Size , which is the number of examples (chosen at random) for a single step. For example, the batch size for SGD is 1. $$total\\,number\\,of\\,trained\\,examples = batch\\,size * steps$$","title":"TensorFlow"},{"location":"tensorflow/#tensor","text":"In TensorFlow, data isn\u2019t stored as integers, floats, or strings. These values are encapsulated in an object called a tensor. import tensorflow as tf # Create TensorFlow object called hello_constant hello_constant = tf.constant('Hello World!') with tf.Session() as sess: # Run the tf.constant operation in the session output = sess.run(hello_constant) print(output)","title":"Tensor"},{"location":"tensorflow/#session","text":"TensorFlow\u2019s api is built around the idea of a computational graph, a way of visualizing a mathematical process. TensorFlow consists of the following two components: a graph protocol buffer a runtime that executes the (distributed) graph These two components are analogous to Python code and the Python interpreter. Just as the Python interpreter is implemented on multiple hardware platforms to run Python code, TensorFlow can run the graph on multiple hardware platforms, including CPU, GPU, and TPU","title":"Session"},{"location":"tensorflow/#a-quick-look-at-the-tfestimator-api","text":"import tensorflow as tf # Set up a linear classifier. classifier = tf.estimator.LinearClassifier(feature_columns) # Train the model on some example data. classifier.train(input_fn=train_input_fn, steps=2000) # Use it to predict. predictions = classifier.predict(input_fn=predict_input_fn)","title":"A Quick Look at the tf.estimator API"},{"location":"tensorflow/#hyperparameters","text":"Steps , which is the total number of training iterations. One step calculates the loss from one batch and uses that value to modify the model's weights once. Batch Size , which is the number of examples (chosen at random) for a single step. For example, the batch size for SGD is 1. $$total\\,number\\,of\\,trained\\,examples = batch\\,size * steps$$","title":"Hyperparameters"},{"location":"terminology/","text":"Model The representation of what an ML system has learned from the training data. Labels A label is the thing we're predicting\u2014the y variable in simple linear regression. The label could be the future price of wheat, the kind of animal shown in a picture, the meaning of an audio clip, or just about anything. Features A feature is an input variable\u2014the x variable in simple linear regression. $$x_1,x_2,x_3,....x_N$$ synthetic feature: A feature not present among the input features, but created from one or more of them. Kinds of synthetic features include: Bucketing a continuous feature into range bins. Multiplying (or dividing) one feature value by other feature value(s) or by itself. Creating a feature cross. Features created by normalizing or scaling alone are not considered synthetic features. Scaling A commonly used practice in feature engineering to tame a feature's range of values to match the range of other features in the dataset. For example, suppose that you want all floating-point features in the dataset to have a range of 0 to 1. Given a particular feature's range of 0 to 500, you could scale that feature by dividing each value by 500. Weight A coefficient for a feature in a linear model, or an edge in a deep network. The goal of training a linear model is to determine the ideal weight for each feature. If a weight is 0, then its corresponding feature does not contribute to the model. Data Set training set: The subset of the dataset used to train a model. test set: The subset of the dataset that you use to test your model after the model has gone through initial vetting by the validation set. validation set: A subset of the dataset\u2014disjoint from the training set\u2014used in validation. temporal data: Data recorded at different points in time. For example, winter coat sales recorded for each day of the year would be temporal data. stationarity: A property of data in a dataset, in which the data distribution stays constant across one or more dimensions. Most commonly, that dimension is time, meaning that data exhibiting stationarity doesn't change over time. For example, data that exhibits stationarity doesn't change from September to December. static model: A model that is trained offline. Examples An example is a particular instance of data, x. We break examples into two categories: labeled examples unlabeled examples A labeled example includes both feature(s) and the label. That is: {features, label}: (x, y) Use labeled examples to train the model. An unlabeled example contains features but not the label. That is: {features, ?}: (x, ?) Once we've trained our model with labeled examples, we use that model to predict the label on unlabeled examples. Models A model defines the relationship between features and label (and are defined by internal parameters, which are learned). For example, a spam detection model might associate certain features strongly with \"spam\". Let's highlight two phases of a model's life: Training means creating or learning the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples. Inference means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y'). For example, during inference, you can predict medianHouseValue for new unlabeled examples. Loss Loss is the penalty for a bad prediction or how far a model's predictions are from its label. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. L1 Loss Loss function based on the absolute value of the difference between the values that a model is predicting and the actual values of the labels. L1 loss is less sensitive to outliers than L2 loss. L2 Loss This function calculates the squares of the difference between a model's predicted value for a labeled example and the actual value of the label. Due to squaring, this loss function amplifies the influence of bad predictions. That is, squared loss reacts more strongly to outliers than L1 loss. (used in linear regression) $$ \\begin{align} L_2 Loss & = (observation - prediction)^2 \\\\ & = (y - y')^2 \\\\ & = \\sum_{(x,y)\\in D}(y-prediction(x))^2 \\end{align} $$ $$\\sum \\text{:We're summing over all examples in the training set.}$$ $$D \\text{: is a data set containing many labeled examples, which are (x,y) pairs.}$$ $$ \\text{ Sometimes useful to average over all examples, } \\text{so divide out by} \\frac{1}{|D|}.$$ Selection Bias Errors in conclusions drawn from sampled data due to a selection process that generates systematic differences between samples observed in the data and those not observed. The following forms of selection bias exist: coverage bias: The population represented in the dataset does not match the population that the ML model is making predictions about. sampling bias: Data is not collected randomly from the target group. non-response bias (also called participation bias): Users from certain groups opt-out of surveys at different rates than users from other groups. Gradient Gradient The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent. $$(y - y')^2$$ The derivative of above with respect to the weights and biases tells us how loss changes for a given example Gradient Descent A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss. Exploding Gradient Problem The tendency for gradients in a deep neural networks (especially recurrent neural networks) to become surprisingly steep (high). Steep gradients result in very large updates to the weights of each node in a deep neural network. Models suffering from the exploding gradient problem become difficult or impossible to train. Gradient clipping can mitigate this problem. Gradient Clipping A commonly used mechanism to mitigate the exploding gradient problem by artificially limiting (clipping) the maximum value of gradients when using gradient descent to train a model. Convergence Informally, often refers to a state reached during training in which training loss and validation loss change very little or not at all with each iteration after a certain number of iterations. In other words, a model reaches convergence when additional training on the current data will not improve the model. In deep learning, loss values sometimes stay constant or nearly so for many iterations before finally descending, temporarily producing a false sense of convergence. Underfitting Producing a model with poor predictive ability because the model hasn't captured the complexity of the training data. Many problems can cause underfitting, including: Training on the wrong set of features. Training for too few epochs or at too low a learning rate. Training with too high a regularization rate. Providing too few hidden layers in a deep neural network. Overfitting The algorithm analyses the data and trains itself to create a high mathematical order model based on the data. $$y = x_1 + w_2x_2^3 + w_3x_3^8$$ These high-order terms let this equation define a precise decision boundary between the positive and negative values, but as a result, the training process has created a model that works very well on training data but poorly when asked to predict values based on data it has not trained - this is the class overfit problem and is an issue that must be handled to create machine learning models that work well not only on the training data but also on real-world data. Regularization , Cross validation , Ensemble learning of which dropout is a part, are all ways to mitigate overfitting. We add an additional parameter where if the model coefficients get too complex we add a penalty to the objective function. This is the technique that we use in regression. Regularization: The penalty on a model's complexity. Different kinds of regularization include: L1 regularization L2 regularization Dropout regularization L1 is a type of regularization that penalizes weights in proportion to the sum of the absolute values of the weights. In models relying on sparse features, L1 regularization helps drive the weights of irrelevant or barely relevant features to exactly 0, which removes those features from the model. Contrast with L2 regularization. L2 is a type of regularization that penalizes weights in proportion to the sum of the squares of the weights. L2 regularization helps drive outlier weights (those with high positive or low negative values) closer to 0 but not quite to 0. (Contrast with L1 regularization.) L2 regularization always improves generalization in linear models. Dropout is a form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization. This is analogous to training the network to emulate an exponentially large ensemble of smaller networks. Regularization rate A scalar value, represented as lambda, specifying the relative importance of the regularization function. The following simplified loss equation shows the regularization rate's influence: $$\\text{minimize(loss function + }\\lambda\\text{(regularization function))}$$ Raising the regularization rate reduces overfitting but may make the model less accurate. Hyperplane A boundary that separates a space into two subspaces. For example, a line is a hyperplane in two dimensions and a plane is a hyperplane in three dimensions. More typically in machine learning, a hyperplane is the boundary separating a high-dimensional space. Kernel Support Vector Machines use hyperplanes to separate positive classes from negative classes, often in a very high-dimensional space. Parameter A variable of a model that the ML system trains on its own. A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data. Often model parameters are estimated using an optimization algorithm, which is a type of efficient search through possible parameter values. They are required by the model when making predictions. They values define the skill of the model on your problem. They are estimated or learned from data. They are often not set manually by the practitioner. They are often saved as part of the learned model. Parameters are key to machine learning algorithms. They are the part of the model that is learned from historical training data. Statistics: In statistics, you may assume a distribution for a variable, such as a Gaussian distribution. Two parameters of the Gaussian distribution are the mean (mu) and the standard deviation (sigma). This holds in machine learning, where these parameters may be estimated from data and used as part of a predictive model. Programming: In programming, you may pass a parameter to a function. In this case, a parameter is a function argument that could have one of a range of values. In machine learning, the specific model you are using is the function and requires parameters in order to make a prediction on new data. Some examples of model parameters include: The weights in an artificial neural network. The support vectors in a support vector machine. The coefficients in a linear regression or logistic regression. Hyperparameter Hyperparameters are the configuration settings used to tune how the model is trained and it is external to the model, whose value cannot be estimated from data. They are often used in processes to help estimate model parameters. They are often specified by the practitioner. They can often be set using heuristics. They are often tuned for a given predictive modeling problem. We cannot know the best value for a hyperparameter on a given problem. We may use rules of thumb, copy values used on other problems, or search for the best value by trial and error. When a machine learning algorithm is tuned for a specific problem, such as when you are using a grid search or a random search, then you are tuning the hyperparameters of the model or order to discover the parameters of the model that result in the most skillful predictions. Hyperparameters are often referred to as model parameters which can make things confusing. A good rule of thumb to overcome this confusion is as follows: If you have to specify a model parameter manually then it is probably a model hyperparameter. Some examples of model hyperparameters include: The learning rate for training a neural network. The C and sigma hyperparameters for support vector machines. The k in k-nearest neighbors. Grid Search is an approach to hyperparameter tuning that will methodically build and evaluate model for each combination of algorithm parameters specified in a grid. Learning Rate A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step. Time Series Analysis A subfield of machine learning and statistics that analyzes temporal data. Many types of machine learning problems require time series analysis, including classification, clustering, forecasting, and anomaly detection. For example, you could use time series analysis to forecast the future sales of winter coats by month based on historical sales data. Keras A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.","title":"Terminology"},{"location":"terminology/#model","text":"The representation of what an ML system has learned from the training data.","title":"Model"},{"location":"terminology/#labels","text":"A label is the thing we're predicting\u2014the y variable in simple linear regression. The label could be the future price of wheat, the kind of animal shown in a picture, the meaning of an audio clip, or just about anything.","title":"Labels"},{"location":"terminology/#features","text":"A feature is an input variable\u2014the x variable in simple linear regression. $$x_1,x_2,x_3,....x_N$$ synthetic feature: A feature not present among the input features, but created from one or more of them. Kinds of synthetic features include: Bucketing a continuous feature into range bins. Multiplying (or dividing) one feature value by other feature value(s) or by itself. Creating a feature cross. Features created by normalizing or scaling alone are not considered synthetic features.","title":"Features"},{"location":"terminology/#scaling","text":"A commonly used practice in feature engineering to tame a feature's range of values to match the range of other features in the dataset. For example, suppose that you want all floating-point features in the dataset to have a range of 0 to 1. Given a particular feature's range of 0 to 500, you could scale that feature by dividing each value by 500.","title":"Scaling"},{"location":"terminology/#weight","text":"A coefficient for a feature in a linear model, or an edge in a deep network. The goal of training a linear model is to determine the ideal weight for each feature. If a weight is 0, then its corresponding feature does not contribute to the model.","title":"Weight"},{"location":"terminology/#data-set","text":"training set: The subset of the dataset used to train a model. test set: The subset of the dataset that you use to test your model after the model has gone through initial vetting by the validation set. validation set: A subset of the dataset\u2014disjoint from the training set\u2014used in validation. temporal data: Data recorded at different points in time. For example, winter coat sales recorded for each day of the year would be temporal data. stationarity: A property of data in a dataset, in which the data distribution stays constant across one or more dimensions. Most commonly, that dimension is time, meaning that data exhibiting stationarity doesn't change over time. For example, data that exhibits stationarity doesn't change from September to December. static model: A model that is trained offline.","title":"Data Set"},{"location":"terminology/#examples","text":"An example is a particular instance of data, x. We break examples into two categories: labeled examples unlabeled examples A labeled example includes both feature(s) and the label. That is: {features, label}: (x, y) Use labeled examples to train the model. An unlabeled example contains features but not the label. That is: {features, ?}: (x, ?) Once we've trained our model with labeled examples, we use that model to predict the label on unlabeled examples.","title":"Examples"},{"location":"terminology/#models","text":"A model defines the relationship between features and label (and are defined by internal parameters, which are learned). For example, a spam detection model might associate certain features strongly with \"spam\". Let's highlight two phases of a model's life: Training means creating or learning the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples. Inference means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y'). For example, during inference, you can predict medianHouseValue for new unlabeled examples.","title":"Models"},{"location":"terminology/#loss","text":"Loss is the penalty for a bad prediction or how far a model's predictions are from its label. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. L1 Loss Loss function based on the absolute value of the difference between the values that a model is predicting and the actual values of the labels. L1 loss is less sensitive to outliers than L2 loss. L2 Loss This function calculates the squares of the difference between a model's predicted value for a labeled example and the actual value of the label. Due to squaring, this loss function amplifies the influence of bad predictions. That is, squared loss reacts more strongly to outliers than L1 loss. (used in linear regression) $$ \\begin{align} L_2 Loss & = (observation - prediction)^2 \\\\ & = (y - y')^2 \\\\ & = \\sum_{(x,y)\\in D}(y-prediction(x))^2 \\end{align} $$ $$\\sum \\text{:We're summing over all examples in the training set.}$$ $$D \\text{: is a data set containing many labeled examples, which are (x,y) pairs.}$$ $$ \\text{ Sometimes useful to average over all examples, } \\text{so divide out by} \\frac{1}{|D|}.$$","title":"Loss"},{"location":"terminology/#selection-bias","text":"Errors in conclusions drawn from sampled data due to a selection process that generates systematic differences between samples observed in the data and those not observed. The following forms of selection bias exist: coverage bias: The population represented in the dataset does not match the population that the ML model is making predictions about. sampling bias: Data is not collected randomly from the target group. non-response bias (also called participation bias): Users from certain groups opt-out of surveys at different rates than users from other groups.","title":"Selection Bias"},{"location":"terminology/#gradient","text":"Gradient The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent. $$(y - y')^2$$ The derivative of above with respect to the weights and biases tells us how loss changes for a given example Gradient Descent A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss. Exploding Gradient Problem The tendency for gradients in a deep neural networks (especially recurrent neural networks) to become surprisingly steep (high). Steep gradients result in very large updates to the weights of each node in a deep neural network. Models suffering from the exploding gradient problem become difficult or impossible to train. Gradient clipping can mitigate this problem. Gradient Clipping A commonly used mechanism to mitigate the exploding gradient problem by artificially limiting (clipping) the maximum value of gradients when using gradient descent to train a model.","title":"Gradient"},{"location":"terminology/#convergence","text":"Informally, often refers to a state reached during training in which training loss and validation loss change very little or not at all with each iteration after a certain number of iterations. In other words, a model reaches convergence when additional training on the current data will not improve the model. In deep learning, loss values sometimes stay constant or nearly so for many iterations before finally descending, temporarily producing a false sense of convergence.","title":"Convergence"},{"location":"terminology/#underfitting","text":"Producing a model with poor predictive ability because the model hasn't captured the complexity of the training data. Many problems can cause underfitting, including: Training on the wrong set of features. Training for too few epochs or at too low a learning rate. Training with too high a regularization rate. Providing too few hidden layers in a deep neural network.","title":"Underfitting"},{"location":"terminology/#overfitting","text":"The algorithm analyses the data and trains itself to create a high mathematical order model based on the data. $$y = x_1 + w_2x_2^3 + w_3x_3^8$$ These high-order terms let this equation define a precise decision boundary between the positive and negative values, but as a result, the training process has created a model that works very well on training data but poorly when asked to predict values based on data it has not trained - this is the class overfit problem and is an issue that must be handled to create machine learning models that work well not only on the training data but also on real-world data. Regularization , Cross validation , Ensemble learning of which dropout is a part, are all ways to mitigate overfitting. We add an additional parameter where if the model coefficients get too complex we add a penalty to the objective function. This is the technique that we use in regression. Regularization: The penalty on a model's complexity. Different kinds of regularization include: L1 regularization L2 regularization Dropout regularization L1 is a type of regularization that penalizes weights in proportion to the sum of the absolute values of the weights. In models relying on sparse features, L1 regularization helps drive the weights of irrelevant or barely relevant features to exactly 0, which removes those features from the model. Contrast with L2 regularization. L2 is a type of regularization that penalizes weights in proportion to the sum of the squares of the weights. L2 regularization helps drive outlier weights (those with high positive or low negative values) closer to 0 but not quite to 0. (Contrast with L1 regularization.) L2 regularization always improves generalization in linear models. Dropout is a form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization. This is analogous to training the network to emulate an exponentially large ensemble of smaller networks. Regularization rate A scalar value, represented as lambda, specifying the relative importance of the regularization function. The following simplified loss equation shows the regularization rate's influence: $$\\text{minimize(loss function + }\\lambda\\text{(regularization function))}$$ Raising the regularization rate reduces overfitting but may make the model less accurate.","title":"Overfitting"},{"location":"terminology/#hyperplane","text":"A boundary that separates a space into two subspaces. For example, a line is a hyperplane in two dimensions and a plane is a hyperplane in three dimensions. More typically in machine learning, a hyperplane is the boundary separating a high-dimensional space. Kernel Support Vector Machines use hyperplanes to separate positive classes from negative classes, often in a very high-dimensional space.","title":"Hyperplane"},{"location":"terminology/#parameter","text":"A variable of a model that the ML system trains on its own. A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data. Often model parameters are estimated using an optimization algorithm, which is a type of efficient search through possible parameter values. They are required by the model when making predictions. They values define the skill of the model on your problem. They are estimated or learned from data. They are often not set manually by the practitioner. They are often saved as part of the learned model. Parameters are key to machine learning algorithms. They are the part of the model that is learned from historical training data. Statistics: In statistics, you may assume a distribution for a variable, such as a Gaussian distribution. Two parameters of the Gaussian distribution are the mean (mu) and the standard deviation (sigma). This holds in machine learning, where these parameters may be estimated from data and used as part of a predictive model. Programming: In programming, you may pass a parameter to a function. In this case, a parameter is a function argument that could have one of a range of values. In machine learning, the specific model you are using is the function and requires parameters in order to make a prediction on new data. Some examples of model parameters include: The weights in an artificial neural network. The support vectors in a support vector machine. The coefficients in a linear regression or logistic regression.","title":"Parameter"},{"location":"terminology/#hyperparameter","text":"Hyperparameters are the configuration settings used to tune how the model is trained and it is external to the model, whose value cannot be estimated from data. They are often used in processes to help estimate model parameters. They are often specified by the practitioner. They can often be set using heuristics. They are often tuned for a given predictive modeling problem. We cannot know the best value for a hyperparameter on a given problem. We may use rules of thumb, copy values used on other problems, or search for the best value by trial and error. When a machine learning algorithm is tuned for a specific problem, such as when you are using a grid search or a random search, then you are tuning the hyperparameters of the model or order to discover the parameters of the model that result in the most skillful predictions. Hyperparameters are often referred to as model parameters which can make things confusing. A good rule of thumb to overcome this confusion is as follows: If you have to specify a model parameter manually then it is probably a model hyperparameter. Some examples of model hyperparameters include: The learning rate for training a neural network. The C and sigma hyperparameters for support vector machines. The k in k-nearest neighbors. Grid Search is an approach to hyperparameter tuning that will methodically build and evaluate model for each combination of algorithm parameters specified in a grid. Learning Rate A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.","title":"Hyperparameter"},{"location":"terminology/#time-series-analysis","text":"A subfield of machine learning and statistics that analyzes temporal data. Many types of machine learning problems require time series analysis, including classification, clustering, forecasting, and anomaly detection. For example, you could use time series analysis to forecast the future sales of winter coats by month based on historical sales data.","title":"Time Series Analysis"},{"location":"terminology/#keras","text":"A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.","title":"Keras"}]}