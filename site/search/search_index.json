{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Machine Learning? Arthur Samuel described it as: \"The field of study that gives computers the ability to learn without being explicitly programmed.\" This is an older, informal definition. Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\" Example : playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning Unsupervised learning Supervised Learning In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. Supervised learning problems are categorized into regression and classification problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. Example 1 : Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. We could turn this example into a classification problem by instead making our output about whether the house \"sells for more or less than the asking price.\" Here we are classifying the houses based on price into two discrete categories. Example 2 : (a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture (b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign. Unsupervised Learning Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables. We can derive this structure by clustering the data based on relationships among the variables in the data. With unsupervised learning there is no feedback based on the prediction results. Example : Clustering : Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering : The \"Cocktail Party Algorithm\", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).","title":"About"},{"location":"#what-is-machine-learning","text":"Arthur Samuel described it as: \"The field of study that gives computers the ability to learn without being explicitly programmed.\" This is an older, informal definition. Tom Mitchell provides a more modern definition: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\" Example : playing checkers. E = the experience of playing many games of checkers T = the task of playing checkers. P = the probability that the program will win the next game. In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning Unsupervised learning","title":"What is Machine Learning?"},{"location":"#supervised-learning","text":"In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output. Supervised learning problems are categorized into regression and classification problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories. Example 1 : Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a continuous output, so this is a regression problem. We could turn this example into a classification problem by instead making our output about whether the house \"sells for more or less than the asking price.\" Here we are classifying the houses based on price into two discrete categories. Example 2 : (a) Regression - Given a picture of a person, we have to predict their age on the basis of the given picture (b) Classification - Given a patient with a tumor, we have to predict whether the tumor is malignant or benign.","title":"Supervised Learning"},{"location":"#unsupervised-learning","text":"Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables. We can derive this structure by clustering the data based on relationships among the variables in the data. With unsupervised learning there is no feedback based on the prediction results. Example : Clustering : Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on. Non-clustering : The \"Cocktail Party Algorithm\", allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).","title":"Unsupervised Learning"},{"location":"ml_workflow/","text":"An orchestrated and repeatable pattern which systematically transforms and processes information to create prediction solutions. Asking the right question Preparing data Selecting the algorithm Training the model Testing the model Solution Statement Use the Machine Learning Workflow to process and transform Pima Indian data to create a prediction model. This model must predict which peopel are likely to develop diabetes with 70% or greater accuracy Tidy Data Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column each observation is a row each type of observational unit is a table Selecting the algorithm We will use our problem knowledge to help us decide the algorithm to use. we will discuss - The role of the algorithm in machine learning process, select our initial algorithm by utilizing the requirements identified in the solution statement as a guide, and discuss at a high level the characteristics of some specific algorithms. Finally select one algorithm to be our initial algorithm, in machine learning we often cycle through the workflow. In our search to find the best solution, it is likely we will need to train and evaluate multiple algorithms. Let's review how the algorithm is involved in the process. When the training function (often named fit in scikit-learn) is called, the algorithm executes its logic and processes the training data. Using the algorithm's logic, the data in analyzed. This analysis evaluates the data with respect to mathematical model and logic associated with the algorithm. The algorithm uses the results of this analysis to adjust internal parameters to produce a model that has been trained to best fit the features in the training data and produce the associated class result. This best fit is defined by evaluating a function specific to the particular algorithm. The fit parameters are stored and the model is now said to be trained. Later, the trained model is called the prediction function (often named predict in scikit-learn). When this prediction function is called, real data is passed to the trained model. Using only the features in the data, the trained model uses its code and parameter values set during training to evaluate the data's features and predict the class result, diabetes or not for this new data. Decision factors to select our initial algorithm: We will use our solution statement and knowledge of the workflow to help guide us in the evaluation of these factors. what Learning Type they support the Result Type the algorithm predicts the Complexity of the algorithm whether the algorithm is Basic or Enhanced Each algorithm has a set of problems with which it works best. One way to divide them is to look at the type of Learning they support. Reading the statement, we see that our solution is about prediction. Prediction means supervised machine learning, so we can eliminate all algorithms that do not support it. Let's see how Result Type can help. Prediction results can be divided into two categories: Regression (Continuous values) Classification (Discrete values) Based on the Statment, the algorithm must support Binary classification. Since this is our initial algorithm, let's stick to the basic algorithms. Selecting Our Initial Algorithm Candidate Algorithms: Naive Bayes Logistic Regression Decision Tree More complex algoritms use these as building blocks. Naive Bayes Algorithm The Naive Bayes algorithm is based on Bayes' Theorem. This theorem calculates a probability of a diabetes by looking at the likelihood of diabetes based on previous data combined with probability of diabetes on nearby feature values. In other words, so how often does the person having high blood pressure correlate to diabetes? It makes the naive assumption that all of the features we pass in are independent of each other and equally impact the result. This assumption that every featuer is independent to the others allows for fast conversions and therefore requires a small amount of data to train. Logistic Regression Algorithm The Logistic Regression algorithm has a somewhat confusing name. In Statistics, Regression often implies continuous values. But Logistics Regression returns a binary result. The algorithm measures the relationship of each feature and weights them based on their impact on the result. The resultant value is mapped against a curve with two values, one and zero, which is equivalent to diabetes or no diabetes. Decision Tree Algorithm The Decision Tree algorithm can be nicely visualized. The algorithm uses a binary tree structure with each node making a decision based upon the values of the feature. At each node, the feature value causes us to go down one path or another. A lot of data may be required to find the value which defines taking one path or another. As we see decision trees have the advantage of having tools available to produce a picture of the tree. This makes it easy to follow along and visualize how the trained model works. Training the Model Letting specific data teach a machine learning algorithm to create a specific prediction model. Why retrain? Retraining will ensure that our model can take advantage of the new data to make better predictions. And also verify the algorithm can still create a high-performance model with the new data. Scikit-learn library Designed to work with NumPy, SciPy and Pandas Toolset for training and evaluation tasks: Data splitting Pre-processing Feature selection Model training Model tuning and offers common interface across algorithms","title":"Machine Learning Workflow"},{"location":"ml_workflow/#solution-statement","text":"Use the Machine Learning Workflow to process and transform Pima Indian data to create a prediction model. This model must predict which peopel are likely to develop diabetes with 70% or greater accuracy","title":"Solution Statement"},{"location":"ml_workflow/#tidy-data","text":"Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column each observation is a row each type of observational unit is a table","title":"Tidy Data"},{"location":"ml_workflow/#selecting-the-algorithm","text":"We will use our problem knowledge to help us decide the algorithm to use. we will discuss - The role of the algorithm in machine learning process, select our initial algorithm by utilizing the requirements identified in the solution statement as a guide, and discuss at a high level the characteristics of some specific algorithms. Finally select one algorithm to be our initial algorithm, in machine learning we often cycle through the workflow. In our search to find the best solution, it is likely we will need to train and evaluate multiple algorithms. Let's review how the algorithm is involved in the process. When the training function (often named fit in scikit-learn) is called, the algorithm executes its logic and processes the training data. Using the algorithm's logic, the data in analyzed. This analysis evaluates the data with respect to mathematical model and logic associated with the algorithm. The algorithm uses the results of this analysis to adjust internal parameters to produce a model that has been trained to best fit the features in the training data and produce the associated class result. This best fit is defined by evaluating a function specific to the particular algorithm. The fit parameters are stored and the model is now said to be trained. Later, the trained model is called the prediction function (often named predict in scikit-learn). When this prediction function is called, real data is passed to the trained model. Using only the features in the data, the trained model uses its code and parameter values set during training to evaluate the data's features and predict the class result, diabetes or not for this new data. Decision factors to select our initial algorithm: We will use our solution statement and knowledge of the workflow to help guide us in the evaluation of these factors. what Learning Type they support the Result Type the algorithm predicts the Complexity of the algorithm whether the algorithm is Basic or Enhanced Each algorithm has a set of problems with which it works best. One way to divide them is to look at the type of Learning they support. Reading the statement, we see that our solution is about prediction. Prediction means supervised machine learning, so we can eliminate all algorithms that do not support it. Let's see how Result Type can help. Prediction results can be divided into two categories: Regression (Continuous values) Classification (Discrete values) Based on the Statment, the algorithm must support Binary classification. Since this is our initial algorithm, let's stick to the basic algorithms.","title":"Selecting the algorithm"},{"location":"ml_workflow/#selecting-our-initial-algorithm","text":"Candidate Algorithms: Naive Bayes Logistic Regression Decision Tree More complex algoritms use these as building blocks.","title":"Selecting Our Initial Algorithm"},{"location":"ml_workflow/#naive-bayes-algorithm","text":"The Naive Bayes algorithm is based on Bayes' Theorem. This theorem calculates a probability of a diabetes by looking at the likelihood of diabetes based on previous data combined with probability of diabetes on nearby feature values. In other words, so how often does the person having high blood pressure correlate to diabetes? It makes the naive assumption that all of the features we pass in are independent of each other and equally impact the result. This assumption that every featuer is independent to the others allows for fast conversions and therefore requires a small amount of data to train.","title":"Naive Bayes Algorithm"},{"location":"ml_workflow/#logistic-regression-algorithm","text":"The Logistic Regression algorithm has a somewhat confusing name. In Statistics, Regression often implies continuous values. But Logistics Regression returns a binary result. The algorithm measures the relationship of each feature and weights them based on their impact on the result. The resultant value is mapped against a curve with two values, one and zero, which is equivalent to diabetes or no diabetes.","title":"Logistic Regression Algorithm"},{"location":"ml_workflow/#decision-tree-algorithm","text":"The Decision Tree algorithm can be nicely visualized. The algorithm uses a binary tree structure with each node making a decision based upon the values of the feature. At each node, the feature value causes us to go down one path or another. A lot of data may be required to find the value which defines taking one path or another. As we see decision trees have the advantage of having tools available to produce a picture of the tree. This makes it easy to follow along and visualize how the trained model works.","title":"Decision Tree Algorithm"},{"location":"ml_workflow/#training-the-model","text":"Letting specific data teach a machine learning algorithm to create a specific prediction model. Why retrain? Retraining will ensure that our model can take advantage of the new data to make better predictions. And also verify the algorithm can still create a high-performance model with the new data.","title":"Training the Model"},{"location":"ml_workflow/#scikit-learn-library","text":"Designed to work with NumPy, SciPy and Pandas Toolset for training and evaluation tasks: Data splitting Pre-processing Feature selection Model training Model tuning and offers common interface across algorithms","title":"Scikit-learn library"},{"location":"week_1/cost_function/","text":"","title":"Cost Function"},{"location":"week_1/cost_function_intuition_1/","text":"","title":"Cost Function Intuition 1"},{"location":"week_1/cost_function_intuition_2/","text":"","title":"Cost Function Intuition 2"},{"location":"week_1/gd_for_linear_regression/","text":"","title":"Gradient Descent For Linear Regression"},{"location":"week_1/gradient_descent/","text":"","title":"Gradient Descent"},{"location":"week_1/gradient_descent_intuition/","text":"","title":"Gradient Descent Intuition"},{"location":"week_1/model_representation/","text":"","title":"Model Representation"}]}